{"created": 1766974030.350595, "duration": 3.101922035217285, "exitcode": 1, "root": "/Users/ruiwang/Desktop/speakingtest/server", "environment": {}, "summary": {"failed": 30, "passed": 153, "total": 183, "collected": 183}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests", "type": "Package"}]}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithXfyun", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithXfyun::test_evaluate_with_xfyun_success", "type": "Coroutine", "lineno": 74}]}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithGemini", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithGemini::test_evaluate_with_gemini_success", "type": "Coroutine", "lineno": 143}]}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestErrors", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestEvaluateTestErrors::test_level_not_found", "type": "Coroutine", "lineno": 203}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestErrors::test_unit_not_found", "type": "Coroutine", "lineno": 226}]}, {"nodeid": "tests/test_api_scoring.py::TestGetAllHistory", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestGetAllHistory::test_get_all_history_success", "type": "Coroutine", "lineno": 256}, {"nodeid": "tests/test_api_scoring.py::TestGetAllHistory::test_get_all_history_empty", "type": "Coroutine", "lineno": 277}]}, {"nodeid": "tests/test_api_scoring.py::TestGetHistoryByStudent", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestGetHistoryByStudent::test_get_student_history_success", "type": "Coroutine", "lineno": 290}, {"nodeid": "tests/test_api_scoring.py::TestGetHistoryByStudent::test_get_student_history_empty", "type": "Coroutine", "lineno": 310}]}, {"nodeid": "tests/test_api_scoring.py::TestGetResultById", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestGetResultById::test_get_result_success", "type": "Coroutine", "lineno": 323}, {"nodeid": "tests/test_api_scoring.py::TestGetResultById::test_get_result_not_found", "type": "Coroutine", "lineno": 343}]}, {"nodeid": "tests/test_api_scoring.py::TestAudioFileHandling", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestAudioFileHandling::test_audio_files_saved", "type": "Coroutine", "lineno": 360}]}, {"nodeid": "tests/test_api_scoring.py::TestCleanupScheduling", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestCleanupScheduling::test_cleanup_scheduled", "type": "Coroutine", "lineno": 427}]}, {"nodeid": "tests/test_api_scoring.py::TestCostCalculation", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestCostCalculation::test_api_cost_calculated", "type": "Coroutine", "lineno": 496}]}, {"nodeid": "tests/test_api_scoring.py", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithXfyun", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithGemini", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestErrors", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestGetAllHistory", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestGetHistoryByStudent", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestGetResultById", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestAudioFileHandling", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestCleanupScheduling", "type": "Class"}, {"nodeid": "tests/test_api_scoring.py::TestCostCalculation", "type": "Class"}]}, {"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens", "outcome": "passed", "result": [{"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens::test_estimate_tokens_with_text_only", "type": "Function", "lineno": 10}, {"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens::test_estimate_tokens_with_audio", "type": "Function", "lineno": 19}, {"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens::test_estimate_tokens_large_audio", "type": "Function", "lineno": 29}]}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost", "outcome": "passed", "result": [{"nodeid": "tests/test_cost_calculator.py::TestCalculateCost::test_calculate_cost_text_only", "type": "Function", "lineno": 41}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost::test_calculate_cost_with_audio", "type": "Function", "lineno": 48}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost::test_calculate_cost_large_values", "type": "Function", "lineno": 57}]}, {"nodeid": "tests/test_cost_calculator.py", "outcome": "passed", "result": [{"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens", "type": "Class"}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost", "type": "Class"}]}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient", "outcome": "passed", "result": [{"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_get_access_token", "type": "Function", "lineno": 24}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_get_access_token_error", "type": "Function", "lineno": 39}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_create_document", "type": "Function", "lineno": 54}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_get_page_block_id", "type": "Function", "lineno": 75}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_export_test_report", "type": "Function", "lineno": 100}]}, {"nodeid": "tests/test_feishu_client.py", "outcome": "passed", "result": [{"nodeid": "tests/test_feishu_client.py::TestFeishuClient", "type": "Class"}]}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupServiceInit", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestFileCleanupServiceInit::test_default_init", "type": "Function", "lineno": 35}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupServiceInit::test_custom_delay_hours", "type": "Function", "lineno": 41}]}, {"nodeid": "tests/test_file_cleanup.py::TestScheduleCleanup", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestScheduleCleanup::test_schedule_cleanup", "type": "Function", "lineno": 51}, {"nodeid": "tests/test_file_cleanup.py::TestScheduleCleanup::test_schedule_multiple_cleanups", "type": "Function", "lineno": 65}]}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay::test_cleanup_after_delay_deletes_files", "type": "Coroutine", "lineno": 84}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay::test_cleanup_handles_nonexistent_files", "type": "Coroutine", "lineno": 117}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay::test_cleanup_handles_file_deletion_errors", "type": "Coroutine", "lineno": 135}]}, {"nodeid": "tests/test_file_cleanup.py::TestCancelCleanup", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestCancelCleanup::test_cancel_existing_task", "type": "Function", "lineno": 167}, {"nodeid": "tests/test_file_cleanup.py::TestCancelCleanup::test_cancel_nonexistent_task", "type": "Function", "lineno": 180}]}, {"nodeid": "tests/test_file_cleanup.py::TestGetPendingCleanups", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestGetPendingCleanups::test_get_pending_cleanups_empty", "type": "Function", "lineno": 192}, {"nodeid": "tests/test_file_cleanup.py::TestGetPendingCleanups::test_get_pending_cleanups_with_tasks", "type": "Function", "lineno": 197}]}, {"nodeid": "tests/test_file_cleanup.py::TestAsyncTaskCleanup", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestAsyncTaskCleanup::test_task_removed_after_completion", "type": "Coroutine", "lineno": 216}]}, {"nodeid": "tests/test_file_cleanup.py::TestDatabaseIntegration", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestDatabaseIntegration::test_database_session_closed", "type": "Coroutine", "lineno": 237}, {"nodeid": "tests/test_file_cleanup.py::TestDatabaseIntegration::test_database_commit_on_success", "type": "Coroutine", "lineno": 253}]}, {"nodeid": "tests/test_file_cleanup.py::TestCancelledErrorHandling", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestCancelledErrorHandling::test_cleanup_handles_cancelled_error", "type": "Coroutine", "lineno": 278}]}, {"nodeid": "tests/test_file_cleanup.py::TestGeneralExceptionHandling", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestGeneralExceptionHandling::test_cleanup_handles_database_errors", "type": "Coroutine", "lineno": 300}]}, {"nodeid": "tests/test_file_cleanup.py::TestGlobalCleanupService", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestGlobalCleanupService::test_global_service_exists", "type": "Function", "lineno": 319}, {"nodeid": "tests/test_file_cleanup.py::TestGlobalCleanupService::test_global_service_default_config", "type": "Function", "lineno": 324}]}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupIntegration", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestFileCleanupIntegration::test_full_cleanup_workflow", "type": "Coroutine", "lineno": 332}]}, {"nodeid": "tests/test_file_cleanup.py", "outcome": "passed", "result": [{"nodeid": "tests/test_file_cleanup.py::TestFileCleanupServiceInit", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestScheduleCleanup", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestCancelCleanup", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestGetPendingCleanups", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestAsyncTaskCleanup", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestDatabaseIntegration", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestCancelledErrorHandling", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestGeneralExceptionHandling", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestGlobalCleanupService", "type": "Class"}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupIntegration", "type": "Class"}]}, {"nodeid": "tests/test_gemini_client.py::TestGeminiClientInit", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestGeminiClientInit::test_init_creates_client", "type": "Function", "lineno": 37}]}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_success", "type": "Function", "lineno": 49}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_with_retry_503", "type": "Function", "lineno": 66}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_max_retries_exceeded", "type": "Function", "lineno": 92}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_non_retryable_error", "type": "Function", "lineno": 111}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_retry_with_exponential_backoff", "type": "Function", "lineno": 130}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_ssl_error_retry", "type": "Function", "lineno": 154}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_retryable_connection_errors", "type": "Function", "lineno": 178}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_file_not_found", "type": "Function", "lineno": 205}]}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio::test_upload_and_analyze_success", "type": "Function", "lineno": 220}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio::test_upload_and_analyze_upload_failure", "type": "Function", "lineno": 243}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio::test_upload_and_analyze_generation_failure", "type": "Function", "lineno": 258}]}, {"nodeid": "tests/test_gemini_client.py::TestModuleConstants", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestModuleConstants::test_model_name", "type": "Function", "lineno": 283}, {"nodeid": "tests/test_gemini_client.py::TestModuleConstants::test_gemini_api_key_exists", "type": "Function", "lineno": 287}]}, {"nodeid": "tests/test_gemini_client.py::TestGlobalGeminiClient", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestGlobalGeminiClient::test_global_client_exists", "type": "Function", "lineno": 296}]}, {"nodeid": "tests/test_gemini_client.py::TestAudioFileHandling", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestAudioFileHandling::test_reads_audio_file_correctly", "type": "Function", "lineno": 307}, {"nodeid": "tests/test_gemini_client.py::TestAudioFileHandling::test_logs_audio_file_size", "type": "Function", "lineno": 321}]}, {"nodeid": "tests/test_gemini_client.py::TestContentType", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestContentType::test_uses_correct_mime_type", "type": "Function", "lineno": 341}]}, {"nodeid": "tests/test_gemini_client.py", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_client.py::TestGeminiClientInit", "type": "Class"}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath", "type": "Class"}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio", "type": "Class"}, {"nodeid": "tests/test_gemini_client.py::TestModuleConstants", "type": "Class"}, {"nodeid": "tests/test_gemini_client.py::TestGlobalGeminiClient", "type": "Class"}, {"nodeid": "tests/test_gemini_client.py::TestAudioFileHandling", "type": "Class"}, {"nodeid": "tests/test_gemini_client.py::TestContentType", "type": "Class"}]}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_five_stars", "type": "Function", "lineno": 17}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_four_stars", "type": "Function", "lineno": 22}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_three_stars", "type": "Function", "lineno": 27}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_two_stars", "type": "Function", "lineno": 32}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_one_star", "type": "Function", "lineno": 37}]}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation::test_create_part1_prompt", "type": "Function", "lineno": 45}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation::test_create_part2_prompt", "type": "Function", "lineno": 57}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation::test_create_part3_prompt", "type": "Function", "lineno": 69}]}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_clean_json", "type": "Function", "lineno": 86}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_json_in_code_block", "type": "Function", "lineno": 95}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_json_with_trailing_comma", "type": "Function", "lineno": 104}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_invalid_json_raises_error", "type": "Function", "lineno": 111}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_questions_format", "type": "Function", "lineno": 116}]}, {"nodeid": "tests/test_gemini_scorer.py", "outcome": "passed", "result": [{"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating", "type": "Class"}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation", "type": "Class"}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse", "type": "Class"}]}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_success", "type": "Function", "lineno": 52}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_partial_score", "type": "Function", "lineno": 71}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_zero_score", "type": "Function", "lineno": 87}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_with_additional_scores", "type": "Function", "lineno": 103}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_missing_score", "type": "Function", "lineno": 127}]}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_six_questions", "type": "Function", "lineno": 147}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_with_start_question_7", "type": "Function", "lineno": 177}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_incomplete_results", "type": "Function", "lineno": 203}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_overall_scores_added", "type": "Function", "lineno": 238}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_default_overall_scores", "type": "Function", "lineno": 265}]}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_twelve_questions", "type": "Function", "lineno": 294}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_incomplete_results", "type": "Function", "lineno": 321}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_returns_overall_scores", "type": "Function", "lineno": 352}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_mixed_scores", "type": "Function", "lineno": 378}]}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration::test_single_question_prompt_contains_question_num", "type": "Function", "lineno": 406}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration::test_group_prompt_contains_all_questions", "type": "Function", "lineno": 423}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration::test_part2_prompt_contains_twelve_questions", "type": "Function", "lineno": 449}]}, {"nodeid": "tests/test_part3_evaluator.py::TestRetryBehavior", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestRetryBehavior::test_single_question_retry_on_failure", "type": "Function", "lineno": 479}, {"nodeid": "tests/test_part3_evaluator.py::TestRetryBehavior::test_group_retry_on_failure", "type": "Function", "lineno": 500}]}, {"nodeid": "tests/test_part3_evaluator.py::TestEdgeCases", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestEdgeCases::test_empty_dialogue_student_options", "type": "Function", "lineno": 531}, {"nodeid": "tests/test_part3_evaluator.py::TestEdgeCases::test_dialogue_missing_student_options", "type": "Function", "lineno": 550}]}, {"nodeid": "tests/test_part3_evaluator.py", "outcome": "passed", "result": [{"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion", "type": "Class"}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group", "type": "Class"}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All", "type": "Class"}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration", "type": "Class"}, {"nodeid": "tests/test_part3_evaluator.py::TestRetryBehavior", "type": "Class"}, {"nodeid": "tests/test_part3_evaluator.py::TestEdgeCases", "type": "Class"}]}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError", "outcome": "passed", "result": [{"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_success_no_retry", "type": "Function", "lineno": 12}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_retry_then_success", "type": "Function", "lineno": 26}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_max_retries_exceeded", "type": "Function", "lineno": 42}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_exponential_backoff", "type": "Function", "lineno": 58}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_multiple_retries_with_backoff", "type": "Function", "lineno": 77}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_location_error_message", "type": "Function", "lineno": 96}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_general_error_message", "type": "Function", "lineno": 115}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_default_parameters", "type": "Function", "lineno": 129}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_custom_max_retries", "type": "Function", "lineno": 138}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_custom_delay", "type": "Function", "lineno": 154}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_custom_backoff", "type": "Function", "lineno": 167}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_function_with_arguments", "type": "Function", "lineno": 185}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_function_with_arguments_retry", "type": "Function", "lineno": 197}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_different_exception_types", "type": "Function", "lineno": 213}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_zero_retries", "type": "Function", "lineno": 224}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_function_returns_none", "type": "Function", "lineno": 237}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_preserves_function_name", "type": "Function", "lineno": 253}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_preserves_function_docstring", "type": "Function", "lineno": 261}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_consecutive_successes", "type": "Function", "lineno": 270}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_long_delay_between_retries", "type": "Function", "lineno": 281}]}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases", "outcome": "passed", "result": [{"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_negative_delay", "type": "Function", "lineno": 297}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_zero_delay", "type": "Function", "lineno": 310}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_large_backoff_multiplier", "type": "Function", "lineno": 323}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_fractional_backoff", "type": "Function", "lineno": 337}]}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorWithRealSleep", "outcome": "passed", "result": [{"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorWithRealSleep::test_actual_delay", "type": "Function", "lineno": 355}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorWithRealSleep::test_cumulative_delay", "type": "Function", "lineno": 369}]}, {"nodeid": "tests/test_retry_decorator.py", "outcome": "passed", "result": [{"nodeid": "tests/test_retry_decorator.py::TestRetryOnError", "type": "Class"}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases", "type": "Class"}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorWithRealSleep", "type": "Class"}]}, {"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit::test_init_success", "type": "Function", "lineno": 60}, {"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit::test_init_missing_app_id", "type": "Function", "lineno": 70}, {"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit::test_init_missing_api_key", "type": "Function", "lineno": 79}]}, {"nodeid": "tests/test_xfyun_client.py::TestCreateUrl", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestCreateUrl::test_create_url_structure", "type": "Function", "lineno": 92}]}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_word_text", "type": "Function", "lineno": 114}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_sentence_text", "type": "Function", "lineno": 123}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_chapter_text", "type": "Function", "lineno": 132}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_unknown_category", "type": "Function", "lineno": 141}]}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_sentence_result", "type": "Function", "lineno": 154}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_word_result", "type": "Function", "lineno": 171}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_invalid_xml", "type": "Function", "lineno": 190}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_syllable_details", "type": "Function", "lineno": 201}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_dp_message", "type": "Function", "lineno": 215}]}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio::test_prepare_pcm_audio", "type": "Function", "lineno": 230}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio::test_prepare_wav_audio", "type": "Function", "lineno": 248}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio::test_prepare_webm_audio", "type": "Function", "lineno": 269}]}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio::test_evaluate_audio_success", "type": "Function", "lineno": 297}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio::test_evaluate_audio_error_code", "type": "Function", "lineno": 339}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio::test_evaluate_audio_websocket_error", "type": "Function", "lineno": 371}]}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudioParameters", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudioParameters::test_evaluate_with_category_read_word", "type": "Function", "lineno": 403}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudioParameters::test_evaluate_with_language_chinese", "type": "Function", "lineno": 442}]}, {"nodeid": "tests/test_xfyun_client.py::TestGetGlobalClient", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestGetGlobalClient::test_get_client_first_time", "type": "Function", "lineno": 485}, {"nodeid": "tests/test_xfyun_client.py::TestGetGlobalClient::test_get_client_missing_config", "type": "Function", "lineno": 495}]}, {"nodeid": "tests/test_xfyun_client.py::TestModuleConstants", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestModuleConstants::test_ise_url", "type": "Function", "lineno": 510}]}, {"nodeid": "tests/test_xfyun_client.py", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestCreateUrl", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudioParameters", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestGetGlobalClient", "type": "Class"}, {"nodeid": "tests/test_xfyun_client.py::TestModuleConstants", "type": "Class"}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_success", "type": "Function", "lineno": 49}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_partial_correct", "type": "Function", "lineno": 65}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_client_none", "type": "Function", "lineno": 93}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_api_error", "type": "Function", "lineno": 104}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_exception", "type": "Function", "lineno": 119}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_low_score", "type": "Function", "lineno": 131}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_success", "type": "Function", "lineno": 160}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_score_conversion", "type": "Function", "lineno": 184}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_client_none", "type": "Function", "lineno": 207}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_with_index", "type": "Function", "lineno": 218}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_success", "type": "Function", "lineno": 243}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_score_distribution", "type": "Function", "lineno": 267}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_client_none", "type": "Function", "lineno": 292}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_uses_chapter_mode", "type": "Function", "lineno": 302}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_correct", "type": "Function", "lineno": 331}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_missed", "type": "Function", "lineno": 335}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_added", "type": "Function", "lineno": 339}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_repeated", "type": "Function", "lineno": 343}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_replaced", "type": "Function", "lineno": 347}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_unknown", "type": "Function", "lineno": 351}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_all_correct", "type": "Function", "lineno": 359}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_mostly_correct", "type": "Function", "lineno": 373}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_half_correct", "type": "Function", "lineno": 390}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_poor", "type": "Function", "lineno": 405}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_excellent", "type": "Function", "lineno": 423}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_good", "type": "Function", "lineno": 428}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_average", "type": "Function", "lineno": 433}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_poor", "type": "Function", "lineno": 438}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_excellent", "type": "Function", "lineno": 447}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_good", "type": "Function", "lineno": 454}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_average", "type": "Function", "lineno": 459}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_low_accuracy", "type": "Function", "lineno": 464}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_low_fluency", "type": "Function", "lineno": 469}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_combined", "type": "Function", "lineno": 474}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestIsXfyunConfigured", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestIsXfyunConfigured::test_configured", "type": "Function", "lineno": 484}, {"nodeid": "tests/test_xfyun_scorer.py::TestIsXfyunConfigured::test_not_configured", "type": "Function", "lineno": 490}]}, {"nodeid": "tests/test_xfyun_scorer.py::TestScoreCalculations", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestScoreCalculations::test_part2_score_calculation", "type": "Function", "lineno": 500}, {"nodeid": "tests/test_xfyun_scorer.py::TestScoreCalculations::test_part2_half_score", "type": "Function", "lineno": 525}]}, {"nodeid": "tests/test_xfyun_scorer.py", "outcome": "passed", "result": [{"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestIsXfyunConfigured", "type": "Class"}, {"nodeid": "tests/test_xfyun_scorer.py::TestScoreCalculations", "type": "Class"}]}, {"nodeid": "tests", "outcome": "passed", "result": [{"nodeid": "tests/test_api_scoring.py", "type": "Module"}, {"nodeid": "tests/test_cost_calculator.py", "type": "Module"}, {"nodeid": "tests/test_feishu_client.py", "type": "Module"}, {"nodeid": "tests/test_file_cleanup.py", "type": "Module"}, {"nodeid": "tests/test_gemini_client.py", "type": "Module"}, {"nodeid": "tests/test_gemini_scorer.py", "type": "Module"}, {"nodeid": "tests/test_part3_evaluator.py", "type": "Module"}, {"nodeid": "tests/test_retry_decorator.py", "type": "Module"}, {"nodeid": "tests/test_xfyun_client.py", "type": "Module"}, {"nodeid": "tests/test_xfyun_scorer.py", "type": "Module"}]}], "tests": [{"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithXfyun::test_evaluate_with_xfyun_success", "lineno": 74, "outcome": "failed", "keywords": ["test_evaluate_with_xfyun_success", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestEvaluateTestWithXfyun", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0009472080000705319, "outcome": "passed"}, "call": {"duration": 0.0004148330000361966, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'"}, "traceback": [{"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 469, "message": ""}, {"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 716, "message": "in inner"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py", "lineno": 127, "message": "in run"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py", "lineno": 719, "message": "in run_until_complete"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1446, "message": "in patched"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "self = <Coroutine test_evaluate_with_xfyun_success>\n\n    def runtest(self) -> None:\n        runner_fixture_id = f\"_{self._loop_scope}_scoped_runner\"\n        runner = self._request.getfixturevalue(runner_fixture_id)\n        context = contextvars.copy_context()\n        synchronized_obj = _synchronize_coroutine(\n            getattr(*self._synchronization_target_attr), runner, context\n        )\n        with MonkeyPatch.context() as c:\n            c.setattr(*self._synchronization_target_attr, synchronized_obj)\n>           super().runtest()\n\nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:469: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:716: in inner\n    runner.run(coro, context=context)\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py:127: in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py:719: in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1446: in patched\n    with self.decoration_helper(patched,\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x124169f30>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00034254100000907783, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestWithGemini::test_evaluate_with_gemini_success", "lineno": 143, "outcome": "failed", "keywords": ["test_evaluate_with_gemini_success", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestEvaluateTestWithGemini", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0007728750000524087, "outcome": "passed"}, "call": {"duration": 0.00022958299996389542, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'"}, "traceback": [{"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 469, "message": ""}, {"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 716, "message": "in inner"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py", "lineno": 127, "message": "in run"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py", "lineno": 719, "message": "in run_until_complete"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1446, "message": "in patched"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "self = <Coroutine test_evaluate_with_gemini_success>\n\n    def runtest(self) -> None:\n        runner_fixture_id = f\"_{self._loop_scope}_scoped_runner\"\n        runner = self._request.getfixturevalue(runner_fixture_id)\n        context = contextvars.copy_context()\n        synchronized_obj = _synchronize_coroutine(\n            getattr(*self._synchronization_target_attr), runner, context\n        )\n        with MonkeyPatch.context() as c:\n            c.setattr(*self._synchronization_target_attr, synchronized_obj)\n>           super().runtest()\n\nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:469: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:716: in inner\n    runner.run(coro, context=context)\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py:127: in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py:719: in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1446: in patched\n    with self.decoration_helper(patched,\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x126428350>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00028779199999462435, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestErrors::test_level_not_found", "lineno": 203, "outcome": "failed", "keywords": ["test_level_not_found", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestEvaluateTestErrors", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0007377089999636155, "outcome": "passed"}, "call": {"duration": 0.0005731669999704536, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/tests/test_api_scoring.py", "lineno": 225, "message": "AssertionError: assert 500 == 404\n +  where 500 = HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Level level1 not found').status_code\n +    where HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Level level1 not found') = <ExceptionInfo HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Level level1 not found') tblen=2>.value"}, "traceback": [{"path": "tests/test_api_scoring.py", "lineno": 225, "message": "AssertionError"}], "longrepr": "self = <tests.test_api_scoring.TestEvaluateTestErrors object at 0x126460190>\nmock_open = <MagicMock name='open' id='4938462752'>\nmock_db = <Mock spec='Session' id='4938462416'>\nmock_part1_audio = <Mock spec='UploadFile' id='4938462080'>\nmock_part2_audio = <Mock spec='UploadFile' id='4938463424'>\n\n    @pytest.mark.asyncio\n    @patch(\"builtins.open\", new_callable=MagicMock)\n    @patch(\"api.scoring.QUESTIONS_FILE\", \"/fake/questions.json\")\n    async def test_level_not_found(self, mock_open, mock_db, mock_part1_audio, mock_part2_audio):\n        \"\"\"\u6d4b\u8bd5\u7ea7\u522b\u4e0d\u5b58\u5728\"\"\"\n        mock_file = MagicMock()\n        mock_file.read.return_value = json.dumps({\"levels\": []}).encode()\n        mock_open.return_value.__enter__.return_value = mock_file\n    \n        from fastapi import HTTPException\n    \n        with pytest.raises(HTTPException) as exc_info:\n            await evaluate_test(\n                student_name=\"TestStudent\",\n                level=\"level1\",\n                unit=\"unit1-3\",\n                part1_audio=mock_part1_audio,\n                part2_audio=mock_part2_audio,\n                db=mock_db\n            )\n    \n>       assert exc_info.value.status_code == 404\nE       AssertionError: assert 500 == 404\nE        +  where 500 = HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Level level1 not found').status_code\nE        +    where HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Level level1 not found') = <ExceptionInfo HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Level level1 not found') tblen=2>.value\n\ntests/test_api_scoring.py:225: AssertionError"}, "teardown": {"duration": 0.0001920830000017304, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestEvaluateTestErrors::test_unit_not_found", "lineno": 226, "outcome": "failed", "keywords": ["test_unit_not_found", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestEvaluateTestErrors", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0009966249999706633, "outcome": "passed"}, "call": {"duration": 0.0005440420000013546, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/tests/test_api_scoring.py", "lineno": 251, "message": "AssertionError: assert 500 == 404\n +  where 500 = HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Unit unit1-3 not found').status_code\n +    where HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Unit unit1-3 not found') = <ExceptionInfo HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Unit unit1-3 not found') tblen=2>.value"}, "traceback": [{"path": "tests/test_api_scoring.py", "lineno": 251, "message": "AssertionError"}], "longrepr": "self = <tests.test_api_scoring.TestEvaluateTestErrors object at 0x1240ae990>\nmock_open = <MagicMock name='open' id='4941873568'>\nmock_db = <Mock spec='Session' id='4941874912'>\nmock_part1_audio = <Mock spec='UploadFile' id='4941875248'>\nmock_part2_audio = <Mock spec='UploadFile' id='4941875920'>\nsample_questions_data = {'levels': [{'level_id': 'level1', 'sections': []}]}\n\n    @pytest.mark.asyncio\n    @patch(\"builtins.open\", new_callable=MagicMock)\n    @patch(\"api.scoring.QUESTIONS_FILE\", \"/fake/questions.json\")\n    async def test_unit_not_found(self, mock_open, mock_db, mock_part1_audio, mock_part2_audio, sample_questions_data):\n        \"\"\"\u6d4b\u8bd5\u5355\u5143\u4e0d\u5b58\u5728\"\"\"\n        # \u79fb\u9664 unit1-3\n        sample_questions_data[\"levels\"][0][\"sections\"] = []\n    \n        mock_file = MagicMock()\n        mock_file.read.return_value = json.dumps(sample_questions_data).encode()\n        mock_open.return_value.__enter__.return_value = mock_file\n    \n        from fastapi import HTTPException\n    \n        with pytest.raises(HTTPException) as exc_info:\n            await evaluate_test(\n                student_name=\"TestStudent\",\n                level=\"level1\",\n                unit=\"unit1-3\",\n                part1_audio=mock_part1_audio,\n                part2_audio=mock_part2_audio,\n                db=mock_db\n            )\n    \n>       assert exc_info.value.status_code == 404\nE       AssertionError: assert 500 == 404\nE        +  where 500 = HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Unit unit1-3 not found').status_code\nE        +    where HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Unit unit1-3 not found') = <ExceptionInfo HTTPException(status_code=500, detail='\u8bc4\u5206\u5931\u8d25: 404: Unit unit1-3 not found') tblen=2>.value\n\ntests/test_api_scoring.py:251: AssertionError"}, "teardown": {"duration": 0.00017891699997107935, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestGetAllHistory::test_get_all_history_success", "lineno": 256, "outcome": "passed", "keywords": ["test_get_all_history_success", "asyncio", "pytestmark", "TestGetAllHistory", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0003918329999805792, "outcome": "passed"}, "call": {"duration": 0.0006252499999845895, "outcome": "passed"}, "teardown": {"duration": 0.00015270900007635646, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestGetAllHistory::test_get_all_history_empty", "lineno": 277, "outcome": "passed", "keywords": ["test_get_all_history_empty", "asyncio", "pytestmark", "TestGetAllHistory", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.00038583299999572773, "outcome": "passed"}, "call": {"duration": 0.00019829099994694843, "outcome": "passed"}, "teardown": {"duration": 0.00013429199998427066, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestGetHistoryByStudent::test_get_student_history_success", "lineno": 290, "outcome": "passed", "keywords": ["test_get_student_history_success", "asyncio", "pytestmark", "TestGetHistoryByStudent", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0003449580000278729, "outcome": "passed"}, "call": {"duration": 0.0003235409999433614, "outcome": "passed"}, "teardown": {"duration": 0.00013037500002610614, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestGetHistoryByStudent::test_get_student_history_empty", "lineno": 310, "outcome": "passed", "keywords": ["test_get_student_history_empty", "asyncio", "pytestmark", "TestGetHistoryByStudent", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.00033862499992665107, "outcome": "passed"}, "call": {"duration": 0.00022008300004472403, "outcome": "passed"}, "teardown": {"duration": 0.00013358399996832304, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestGetResultById::test_get_result_success", "lineno": 323, "outcome": "passed", "keywords": ["test_get_result_success", "asyncio", "pytestmark", "TestGetResultById", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.00034383300010176754, "outcome": "passed"}, "call": {"duration": 0.00021108299995376, "outcome": "passed"}, "teardown": {"duration": 0.00012470800004393823, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestGetResultById::test_get_result_not_found", "lineno": 343, "outcome": "passed", "keywords": ["test_get_result_not_found", "asyncio", "pytestmark", "TestGetResultById", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.00032945899999958783, "outcome": "passed"}, "call": {"duration": 0.00018604199999572302, "outcome": "passed"}, "teardown": {"duration": 0.00012120799999593146, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestAudioFileHandling::test_audio_files_saved", "lineno": 360, "outcome": "failed", "keywords": ["test_audio_files_saved", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestAudioFileHandling", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.000588083000025108, "outcome": "passed"}, "call": {"duration": 0.0002285410000695265, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'"}, "traceback": [{"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 469, "message": ""}, {"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 716, "message": "in inner"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py", "lineno": 127, "message": "in run"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py", "lineno": 719, "message": "in run_until_complete"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1446, "message": "in patched"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "self = <Coroutine test_audio_files_saved>\n\n    def runtest(self) -> None:\n        runner_fixture_id = f\"_{self._loop_scope}_scoped_runner\"\n        runner = self._request.getfixturevalue(runner_fixture_id)\n        context = contextvars.copy_context()\n        synchronized_obj = _synchronize_coroutine(\n            getattr(*self._synchronization_target_attr), runner, context\n        )\n        with MonkeyPatch.context() as c:\n            c.setattr(*self._synchronization_target_attr, synchronized_obj)\n>           super().runtest()\n\nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:469: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:716: in inner\n    runner.run(coro, context=context)\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py:127: in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py:719: in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1446: in patched\n    with self.decoration_helper(patched,\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x126441630>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00024383300001318275, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestCleanupScheduling::test_cleanup_scheduled", "lineno": 427, "outcome": "failed", "keywords": ["test_cleanup_scheduled", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestCleanupScheduling", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0007095419999814112, "outcome": "passed"}, "call": {"duration": 0.0006126250000306754, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'"}, "traceback": [{"path": "tests/test_api_scoring.py", "lineno": 480, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "self = <tests.test_api_scoring.TestCleanupScheduling object at 0x1264611d0>\nmock_path = <MagicMock name='Path' id='4941888352'>\nmock_open = <MagicMock name='open' id='4941887008'>\nmock_part2 = <MagicMock name='evaluate_part2_all_with_xfyun' id='4941886336'>\nmock_part1 = <MagicMock name='evaluate_words_with_xfyun' id='4941886000'>\nmock_xfyun = <MagicMock name='is_xfyun_configured' id='4941885664'>\nmock_db = <Mock spec='Session' id='4941888688'>\nmock_part1_audio = <Mock spec='UploadFile' id='4941889024'>\nmock_part2_audio = <Mock spec='UploadFile' id='4941888016'>\nsample_questions_data = {'levels': [{'level_id': 'level1', 'sections': [{'parts': [{...}, {...}], 'section_id': 'unit1-3'}]}]}\n\n    @pytest.mark.asyncio\n    @patch(\"api.scoring.is_xfyun_configured\", return_value=True)\n    @patch(\"api.scoring.evaluate_words_with_xfyun\")\n    @patch(\"api.scoring.evaluate_part2_all_with_xfyun\")\n    @patch(\"builtins.open\", new_callable=MagicMock)\n    @patch(\"api.scoring.QUESTIONS_FILE\", \"/fake/questions.json\")\n    @patch(\"api.scoring.Path\")\n    async def test_cleanup_scheduled(\n        self, mock_path, mock_open, mock_part2, mock_part1, mock_xfyun,\n        mock_db, mock_part1_audio, mock_part2_audio, sample_questions_data\n    ):\n        \"\"\"\u6d4b\u8bd5\u6e05\u7406\u4efb\u52a1\u88ab\u8c03\u5ea6\"\"\"\n        # Mock \u6587\u4ef6\n        mock_file = MagicMock()\n        mock_file.read.return_value = json.dumps(sample_questions_data).encode()\n        mock_open.return_value.__enter__.return_value = mock_file\n    \n        mock_upload_dir = Mock()\n        mock_upload_dir.mkdir = Mock()\n        mock_path.return_value = mock_upload_dir\n    \n        # Mock \u8baf\u98de\u7ed3\u679c\n        mock_part1.return_value = {\n            \"score\": 3,\n            \"total\": 3,\n            \"correct_words\": [],\n            \"incorrect_words\": [],\n            \"accuracy_score\": 90.0,\n            \"fluency_score\": 85.0,\n            \"feedback\": \"\u4f18\u79c0\"\n        }\n    \n        mock_part2.return_value = {\n            \"total_score\": 20,\n            \"question_scores\": [],\n            \"summary\": {\"fluency_score\": 8.0, \"pronunciation_score\": 7.0, \"confidence_score\": 8.0},\n            \"feedback\": \"\u826f\u597d\"\n        }\n    \n        # Mock \u6e05\u7406\u670d\u52a1\n        mock_cleanup_service = Mock()\n        mock_cleanup_service.schedule_cleanup = Mock()\n    \n        # Mock \u6570\u636e\u5e93\n        mock_test_record = Mock()\n        mock_test_record.id = 1\n        mock_test_record.part_scores = []\n        mock_db.add = Mock()\n        mock_db.flush = Mock()\n        mock_db.commit = Mock()\n        mock_db.refresh = Mock()\n    \n>       with patch(\"api.scoring.cleanup_service\", mock_cleanup_service):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests/test_api_scoring.py:480: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12658e430>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'cleanup_service'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.0002869999999575157, "outcome": "passed"}}, {"nodeid": "tests/test_api_scoring.py::TestCostCalculation::test_api_cost_calculated", "lineno": 496, "outcome": "failed", "keywords": ["test_api_cost_calculated", "asyncio", "__wrapped__", "patchings", "pytestmark", "TestCostCalculation", "test_api_scoring.py", "tests", "server", ""], "setup": {"duration": 0.0007322080000449205, "outcome": "passed"}, "call": {"duration": 0.000217415999941295, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'calculate_cost'"}, "traceback": [{"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 469, "message": ""}, {"path": "venv/lib/python3.14/site-packages/pytest_asyncio/plugin.py", "lineno": 716, "message": "in inner"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py", "lineno": 127, "message": "in run"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py", "lineno": 719, "message": "in run_until_complete"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1446, "message": "in patched"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "self = <Coroutine test_api_cost_calculated>\n\n    def runtest(self) -> None:\n        runner_fixture_id = f\"_{self._loop_scope}_scoped_runner\"\n        runner = self._request.getfixturevalue(runner_fixture_id)\n        context = contextvars.copy_context()\n        synchronized_obj = _synchronize_coroutine(\n            getattr(*self._synchronization_target_attr), runner, context\n        )\n        with MonkeyPatch.context() as c:\n            c.setattr(*self._synchronization_target_attr, synchronized_obj)\n>           super().runtest()\n\nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:469: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nvenv/lib/python3.14/site-packages/pytest_asyncio/plugin.py:716: in inner\n    runner.run(coro, context=context)\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/runners.py:127: in run\n    return self._loop.run_until_complete(task)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/base_events.py:719: in run_until_complete\n    return future.result()\n           ^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1446: in patched\n    with self.decoration_helper(patched,\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x126442430>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'api.scoring' from '/Users/ruiwang/Desktop/speakingtest/server/api/scoring.py'> does not have the attribute 'calculate_cost'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.0002874999998994099, "outcome": "passed"}}, {"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens::test_estimate_tokens_with_text_only", "lineno": 10, "outcome": "passed", "keywords": ["test_estimate_tokens_with_text_only", "TestEstimateTokens", "test_cost_calculator.py", "tests", "server", ""], "setup": {"duration": 6.133299996236019e-05, "outcome": "passed"}, "call": {"duration": 6.062499994641257e-05, "outcome": "passed"}, "teardown": {"duration": 3.60420000333761e-05, "outcome": "passed"}}, {"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens::test_estimate_tokens_with_audio", "lineno": 19, "outcome": "passed", "keywords": ["test_estimate_tokens_with_audio", "TestEstimateTokens", "test_cost_calculator.py", "tests", "server", ""], "setup": {"duration": 4.124999998111889e-05, "outcome": "passed"}, "call": {"duration": 4.704200000560377e-05, "outcome": "passed"}, "teardown": {"duration": 3.220799999326118e-05, "outcome": "passed"}}, {"nodeid": "tests/test_cost_calculator.py::TestEstimateTokens::test_estimate_tokens_large_audio", "lineno": 29, "outcome": "passed", "keywords": ["test_estimate_tokens_large_audio", "TestEstimateTokens", "test_cost_calculator.py", "tests", "server", ""], "setup": {"duration": 3.891599999406026e-05, "outcome": "passed"}, "call": {"duration": 4.770900000039546e-05, "outcome": "passed"}, "teardown": {"duration": 3.4916999993583886e-05, "outcome": "passed"}}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost::test_calculate_cost_text_only", "lineno": 41, "outcome": "passed", "keywords": ["test_calculate_cost_text_only", "TestCalculateCost", "test_cost_calculator.py", "tests", "server", ""], "setup": {"duration": 3.9875000084066414e-05, "outcome": "passed"}, "call": {"duration": 4.0708000028644165e-05, "outcome": "passed"}, "teardown": {"duration": 3.091599990057148e-05, "outcome": "passed"}}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost::test_calculate_cost_with_audio", "lineno": 48, "outcome": "passed", "keywords": ["test_calculate_cost_with_audio", "TestCalculateCost", "test_cost_calculator.py", "tests", "server", ""], "setup": {"duration": 3.7833000078535406e-05, "outcome": "passed"}, "call": {"duration": 4.1667000004963484e-05, "outcome": "passed"}, "teardown": {"duration": 3.145799996673304e-05, "outcome": "passed"}}, {"nodeid": "tests/test_cost_calculator.py::TestCalculateCost::test_calculate_cost_large_values", "lineno": 57, "outcome": "passed", "keywords": ["test_calculate_cost_large_values", "TestCalculateCost", "test_cost_calculator.py", "tests", "server", ""], "setup": {"duration": 3.7666999901375675e-05, "outcome": "passed"}, "call": {"duration": 4.2416000042067026e-05, "outcome": "passed"}, "teardown": {"duration": 3.5749999938161636e-05, "outcome": "passed"}}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_get_access_token", "lineno": 24, "outcome": "passed", "keywords": ["test_get_access_token", "__wrapped__", "patchings", "TestFeishuClient", "test_feishu_client.py", "tests", "server", ""], "setup": {"duration": 0.0002536660000487245, "outcome": "passed"}, "call": {"duration": 0.0002142079999885027, "outcome": "passed"}, "teardown": {"duration": 3.870799992000684e-05, "outcome": "passed"}}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_get_access_token_error", "lineno": 39, "outcome": "passed", "keywords": ["test_get_access_token_error", "__wrapped__", "patchings", "TestFeishuClient", "test_feishu_client.py", "tests", "server", ""], "setup": {"duration": 0.00021533299991460808, "outcome": "passed"}, "call": {"duration": 0.00017524999998386193, "outcome": "passed"}, "teardown": {"duration": 3.558299999895098e-05, "outcome": "passed"}}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_create_document", "lineno": 54, "outcome": "passed", "keywords": ["test_create_document", "__wrapped__", "patchings", "TestFeishuClient", "test_feishu_client.py", "tests", "server", ""], "setup": {"duration": 0.000203333000058592, "outcome": "passed"}, "call": {"duration": 0.00020258300003206386, "outcome": "passed", "stdout": "\u2705 \u521b\u5efa\u98de\u4e66\u6587\u6863\u6210\u529f: docx_abc123\n"}, "teardown": {"duration": 3.862500000195723e-05, "outcome": "passed"}}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_get_page_block_id", "lineno": 75, "outcome": "passed", "keywords": ["test_get_page_block_id", "__wrapped__", "patchings", "TestFeishuClient", "test_feishu_client.py", "tests", "server", ""], "setup": {"duration": 0.00019912499999463762, "outcome": "passed"}, "call": {"duration": 0.0001537499999813008, "outcome": "passed"}, "teardown": {"duration": 3.654200008895714e-05, "outcome": "passed"}}, {"nodeid": "tests/test_feishu_client.py::TestFeishuClient::test_export_test_report", "lineno": 100, "outcome": "passed", "keywords": ["test_export_test_report", "__wrapped__", "patchings", "TestFeishuClient", "test_feishu_client.py", "tests", "server", ""], "setup": {"duration": 0.00019333299997015274, "outcome": "passed"}, "call": {"duration": 0.0003178749999506181, "outcome": "passed", "stdout": "\u2705 \u521b\u5efa\u98de\u4e66\u6587\u6863\u6210\u529f: docx_test123\n\u2705 \u5185\u5bb9\u5df2\u6210\u529f\u6dfb\u52a0\u5230\u6587\u6863\n\ud83d\udcc4 \u6d4b\u8bd5\u62a5\u544a\u5df2\u5bfc\u51fa\u5230\u98de\u4e66: https://feishu.cn/docx/docx_test123\n"}, "teardown": {"duration": 3.8541999970220786e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupServiceInit::test_default_init", "lineno": 35, "outcome": "passed", "keywords": ["test_default_init", "TestFileCleanupServiceInit", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 4.0125000055013516e-05, "outcome": "passed"}, "call": {"duration": 4.466699999738921e-05, "outcome": "passed"}, "teardown": {"duration": 3.979199993864313e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupServiceInit::test_custom_delay_hours", "lineno": 41, "outcome": "passed", "keywords": ["test_custom_delay_hours", "TestFileCleanupServiceInit", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 5.645800001730095e-05, "outcome": "passed"}, "call": {"duration": 6.099999995967664e-05, "outcome": "passed"}, "teardown": {"duration": 6.529200004479208e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestScheduleCleanup::test_schedule_cleanup", "lineno": 51, "outcome": "failed", "keywords": ["test_schedule_cleanup", "TestScheduleCleanup", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 5.3499999921768904e-05, "outcome": "passed"}, "call": {"duration": 6.537499996284168e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError: no running event loop"}, "traceback": [{"path": "tests/test_file_cleanup.py", "lineno": 58, "message": ""}, {"path": "services/file_cleanup.py", "lineno": 37, "message": "in schedule_cleanup"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError"}], "longrepr": "self = <tests.test_file_cleanup.TestScheduleCleanup object at 0x126460690>\n\n    def test_schedule_cleanup(self):\n        \"\"\"\u6d4b\u8bd5\u8c03\u5ea6\u6e05\u7406\u4efb\u52a1\"\"\"\n        service = FileCleanupService(cleanup_delay_hours=0)  # 0\u5c0f\u65f6\u7528\u4e8e\u5feb\u901f\u6d4b\u8bd5\n        test_record_id = 123\n        audio_files = [\"/path/to/audio1.m4a\", \"/path/to/audio2.m4a\"]\n    \n>       service.schedule_cleanup(test_record_id, audio_files)\n\ntests/test_file_cleanup.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nservices/file_cleanup.py:37: in schedule_cleanup\n    task = asyncio.create_task(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncoro = <coroutine object FileCleanupService._cleanup_after_delay at 0x126846c00>\nkwargs = {}\n\n    def create_task(coro, **kwargs):\n        \"\"\"Schedule the execution of a coroutine object in a spawn task.\n    \n        Return a Task object.\n        \"\"\"\n>       loop = events.get_running_loop()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nE       RuntimeError: no running event loop\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py:394: RuntimeError"}, "teardown": {"duration": 5.4750000003878085e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestScheduleCleanup::test_schedule_multiple_cleanups", "lineno": 65, "outcome": "failed", "keywords": ["test_schedule_multiple_cleanups", "TestScheduleCleanup", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 4.93750000032378e-05, "outcome": "passed"}, "call": {"duration": 6.0165999911987456e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError: no running event loop"}, "traceback": [{"path": "tests/test_file_cleanup.py", "lineno": 70, "message": ""}, {"path": "services/file_cleanup.py", "lineno": 37, "message": "in schedule_cleanup"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError"}], "longrepr": "self = <tests.test_file_cleanup.TestScheduleCleanup object at 0x126460550>\n\n    def test_schedule_multiple_cleanups(self):\n        \"\"\"\u6d4b\u8bd5\u8c03\u5ea6\u591a\u4e2a\u6e05\u7406\u4efb\u52a1\"\"\"\n        service = FileCleanupService(cleanup_delay_hours=0)\n    \n>       service.schedule_cleanup(1, [\"/path1.m4a\"])\n\ntests/test_file_cleanup.py:70: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nservices/file_cleanup.py:37: in schedule_cleanup\n    task = asyncio.create_task(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncoro = <coroutine object FileCleanupService._cleanup_after_delay at 0x126846d40>\nkwargs = {}\n\n    def create_task(coro, **kwargs):\n        \"\"\"Schedule the execution of a coroutine object in a spawn task.\n    \n        Return a Task object.\n        \"\"\"\n>       loop = events.get_running_loop()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nE       RuntimeError: no running event loop\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py:394: RuntimeError"}, "teardown": {"duration": 7.045800009564118e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay::test_cleanup_after_delay_deletes_files", "lineno": 84, "outcome": "passed", "keywords": ["test_cleanup_after_delay_deletes_files", "asyncio", "pytestmark", "TestCleanupAfterDelay", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.003047959000014089, "outcome": "passed"}, "call": {"duration": 0.0006616250000206492, "outcome": "passed", "stdout": "\u2705 \u5df2\u5220\u9664: audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96643/3\u4e2a\u6587\u4ef6\n"}, "teardown": {"duration": 0.0001559580000503047, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay::test_cleanup_handles_nonexistent_files", "lineno": 117, "outcome": "passed", "keywords": ["test_cleanup_handles_nonexistent_files", "asyncio", "pytestmark", "TestCleanupAfterDelay", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.00012100000003556488, "outcome": "passed"}, "call": {"duration": 0.0003388330000007045, "outcome": "passed", "stdout": "\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96640/2\u4e2a\u6587\u4ef6\n"}, "teardown": {"duration": 0.0001262499999938882, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestCleanupAfterDelay::test_cleanup_handles_file_deletion_errors", "lineno": 135, "outcome": "passed", "keywords": ["test_cleanup_handles_file_deletion_errors", "asyncio", "pytestmark", "TestCleanupAfterDelay", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.0005349169999817605, "outcome": "passed"}, "call": {"duration": 0.0004776670000410377, "outcome": "passed", "stdout": "\u274c \u5220\u9664\u5931\u8d25: /private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_cleanup_handles_file_dele0/audio_0.m4a, \u9519\u8bef: Permission denied: /private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_cleanup_handles_file_dele0/audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96642/3\u4e2a\u6587\u4ef6\n"}, "teardown": {"duration": 0.0001420410000037009, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestCancelCleanup::test_cancel_existing_task", "lineno": 167, "outcome": "failed", "keywords": ["test_cancel_existing_task", "TestCancelCleanup", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 4.741700001886784e-05, "outcome": "passed"}, "call": {"duration": 6.045899999662652e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError: no running event loop"}, "traceback": [{"path": "tests/test_file_cleanup.py", "lineno": 173, "message": ""}, {"path": "services/file_cleanup.py", "lineno": 37, "message": "in schedule_cleanup"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError"}], "longrepr": "self = <tests.test_file_cleanup.TestCancelCleanup object at 0x126462350>\n\n    def test_cancel_existing_task(self):\n        \"\"\"\u6d4b\u8bd5\u53d6\u6d88\u5b58\u5728\u7684\u4efb\u52a1\"\"\"\n        service = FileCleanupService(cleanup_delay_hours=0)\n        test_record_id = 123\n    \n>       service.schedule_cleanup(test_record_id, [\"/path.m4a\"])\n\ntests/test_file_cleanup.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nservices/file_cleanup.py:37: in schedule_cleanup\n    task = asyncio.create_task(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncoro = <coroutine object FileCleanupService._cleanup_after_delay at 0x126846e80>\nkwargs = {}\n\n    def create_task(coro, **kwargs):\n        \"\"\"Schedule the execution of a coroutine object in a spawn task.\n    \n        Return a Task object.\n        \"\"\"\n>       loop = events.get_running_loop()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nE       RuntimeError: no running event loop\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py:394: RuntimeError"}, "teardown": {"duration": 6.454200001826393e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestCancelCleanup::test_cancel_nonexistent_task", "lineno": 180, "outcome": "passed", "keywords": ["test_cancel_nonexistent_task", "TestCancelCleanup", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 4.791699996076204e-05, "outcome": "passed"}, "call": {"duration": 5.02919999689766e-05, "outcome": "passed"}, "teardown": {"duration": 3.583399995932268e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestGetPendingCleanups::test_get_pending_cleanups_empty", "lineno": 192, "outcome": "passed", "keywords": ["test_get_pending_cleanups_empty", "TestGetPendingCleanups", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 3.979200005232997e-05, "outcome": "passed"}, "call": {"duration": 4.291699997338583e-05, "outcome": "passed"}, "teardown": {"duration": 3.312499995899998e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestGetPendingCleanups::test_get_pending_cleanups_with_tasks", "lineno": 197, "outcome": "failed", "keywords": ["test_get_pending_cleanups_with_tasks", "TestGetPendingCleanups", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 3.7916999986009614e-05, "outcome": "passed"}, "call": {"duration": 4.945899991071201e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError: no running event loop"}, "traceback": [{"path": "tests/test_file_cleanup.py", "lineno": 204, "message": ""}, {"path": "services/file_cleanup.py", "lineno": 37, "message": "in schedule_cleanup"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py", "lineno": 394, "message": "RuntimeError"}], "longrepr": "self = <tests.test_file_cleanup.TestGetPendingCleanups object at 0x126462850>\n\n    def test_get_pending_cleanups_with_tasks(self):\n        \"\"\"\u6d4b\u8bd5\u6709\u4efb\u52a1\u65f6\u7684\u8ba1\u6570\"\"\"\n        service = FileCleanupService(cleanup_delay_hours=0)\n    \n        assert service.get_pending_cleanups() == 0\n    \n>       service.schedule_cleanup(1, [\"/path1.m4a\"])\n\ntests/test_file_cleanup.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nservices/file_cleanup.py:37: in schedule_cleanup\n    task = asyncio.create_task(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ncoro = <coroutine object FileCleanupService._cleanup_after_delay at 0x126847100>\nkwargs = {}\n\n    def create_task(coro, **kwargs):\n        \"\"\"Schedule the execution of a coroutine object in a spawn task.\n    \n        Return a Task object.\n        \"\"\"\n>       loop = events.get_running_loop()\n               ^^^^^^^^^^^^^^^^^^^^^^^^^\nE       RuntimeError: no running event loop\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/asyncio/tasks.py:394: RuntimeError"}, "teardown": {"duration": 5.7291999951303296e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestAsyncTaskCleanup::test_task_removed_after_completion", "lineno": 216, "outcome": "passed", "keywords": ["test_task_removed_after_completion", "asyncio", "pytestmark", "TestAsyncTaskCleanup", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.0007289579999678608, "outcome": "passed"}, "call": {"duration": 0.0006197079999310517, "outcome": "passed", "stdout": "\u2705 \u5df2\u5220\u9664: audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96643/3\u4e2a\u6587\u4ef6\n"}, "teardown": {"duration": 0.00017049999996743281, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestDatabaseIntegration::test_database_session_closed", "lineno": 237, "outcome": "passed", "keywords": ["test_database_session_closed", "asyncio", "pytestmark", "TestDatabaseIntegration", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.0006236659999103722, "outcome": "passed"}, "call": {"duration": 0.0004938749999610081, "outcome": "passed", "stdout": "\u2705 \u5df2\u5220\u9664: audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96643/3\u4e2a\u6587\u4ef6\n"}, "teardown": {"duration": 0.00018699999998261774, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestDatabaseIntegration::test_database_commit_on_success", "lineno": 253, "outcome": "passed", "keywords": ["test_database_commit_on_success", "asyncio", "pytestmark", "TestDatabaseIntegration", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.0007984170000554514, "outcome": "passed"}, "call": {"duration": 0.0005252500000096916, "outcome": "passed", "stdout": "\u2705 \u5df2\u5220\u9664: audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96643/3\u4e2a\u6587\u4ef6\n"}, "teardown": {"duration": 0.00014766699996471289, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestCancelledErrorHandling::test_cleanup_handles_cancelled_error", "lineno": 278, "outcome": "passed", "keywords": ["test_cleanup_handles_cancelled_error", "asyncio", "pytestmark", "TestCancelledErrorHandling", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.00013129100000242033, "outcome": "passed"}, "call": {"duration": 0.0001395000000457003, "outcome": "passed"}, "teardown": {"duration": 0.0001289580000047863, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestGeneralExceptionHandling::test_cleanup_handles_database_errors", "lineno": 300, "outcome": "passed", "keywords": ["test_cleanup_handles_database_errors", "asyncio", "pytestmark", "TestGeneralExceptionHandling", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.0005579589999342716, "outcome": "passed"}, "call": {"duration": 0.0003484169999410369, "outcome": "passed", "stdout": "\u2705 \u5df2\u5220\u9664: audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\u274c \u6e05\u7406\u4efb\u52a1\u5931\u8d25: \u6d4b\u8bd5#123, \u9519\u8bef: Database connection lost\n"}, "teardown": {"duration": 0.00013000000001284207, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestGlobalCleanupService::test_global_service_exists", "lineno": 319, "outcome": "passed", "keywords": ["test_global_service_exists", "TestGlobalCleanupService", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 4.2290999999750056e-05, "outcome": "passed"}, "call": {"duration": 4.245799993896071e-05, "outcome": "passed"}, "teardown": {"duration": 3.170800005136698e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestGlobalCleanupService::test_global_service_default_config", "lineno": 324, "outcome": "passed", "keywords": ["test_global_service_default_config", "TestGlobalCleanupService", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 3.85000000733271e-05, "outcome": "passed"}, "call": {"duration": 4.208300003938348e-05, "outcome": "passed"}, "teardown": {"duration": 3.31659999801559e-05, "outcome": "passed"}}, {"nodeid": "tests/test_file_cleanup.py::TestFileCleanupIntegration::test_full_cleanup_workflow", "lineno": 332, "outcome": "passed", "keywords": ["test_full_cleanup_workflow", "asyncio", "pytestmark", "TestFileCleanupIntegration", "test_file_cleanup.py", "tests", "server", ""], "setup": {"duration": 0.0005212080000092101, "outcome": "passed"}, "call": {"duration": 0.006943916000068384, "outcome": "passed", "stdout": "\ud83d\uddd1\ufe0f \u5df2\u8c03\u5ea6\u6e05\u7406\u4efb\u52a1: \u6d4b\u8bd5#123, 3\u4e2a\u6587\u4ef6, 0\u5c0f\u65f6\u540e\u6e05\u7406\n\u2705 \u5df2\u5220\u9664: audio_0.m4a\n\u2705 \u5df2\u5220\u9664: audio_1.m4a\n\u2705 \u5df2\u5220\u9664: audio_2.m4a\n\ud83d\uddd1\ufe0f \u6e05\u7406\u5b8c\u6210: \u6d4b\u8bd5#123, \u5220\u96643/3\u4e2a\u6587\u4ef6\n\u274c \u6e05\u7406\u4efb\u52a1\u5931\u8d25: \u6d4b\u8bd5#123, \u9519\u8bef: (sqlite3.OperationalError) no such column: audio_files.file_size\n[SQL: SELECT audio_files.id AS audio_files_id, audio_files.test_record_id AS audio_files_test_record_id, audio_files.part_number AS audio_files_part_number, audio_files.file_path AS audio_files_file_path, audio_files.file_size AS audio_files_file_size, audio_files.created_at AS audio_files_created_at, audio_files.deleted_at AS audio_files_deleted_at \nFROM audio_files \nWHERE audio_files.test_record_id = ?]\n[parameters: (123,)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"}, "teardown": {"duration": 0.0001612089999980526, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestGeminiClientInit::test_init_creates_client", "lineno": 37, "outcome": "passed", "keywords": ["test_init_creates_client", "__wrapped__", "patchings", "TestGeminiClientInit", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 4.679200003465667e-05, "outcome": "passed"}, "call": {"duration": 0.00022799999999278953, "outcome": "passed"}, "teardown": {"duration": 4.158299998380244e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_success", "lineno": 49, "outcome": "passed", "keywords": ["test_analyze_audio_success", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00045237500000894215, "outcome": "passed"}, "call": {"duration": 0.0009979579999708221, "outcome": "passed", "stdout": "\ud83d\udcca \u5c1d\u8bd5 1/3: \u97f3\u9891\u5927\u5c0f 0.0KB\n"}, "teardown": {"duration": 4.712499992365338e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_with_retry_503", "lineno": 66, "outcome": "failed", "keywords": ["test_analyze_audio_with_retry_503", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0003437500000700311, "outcome": "passed"}, "call": {"duration": 0.0005673750000596556, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.gemini_client' has no attribute 'time'"}, "traceback": [{"path": "tests/test_gemini_client.py", "lineno": 87, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "self = <tests.test_gemini_client.TestAnalyzeAudioFromPath object at 0x126463750>\nmock_file = <MagicMock name='open' id='4941368016'>\nmock_genai_client = <MagicMock name='Client' id='4941381120'>\nsample_audio_file = '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_analyze_audio_with_retry_0/test_audio.webm'\n\n    @patch(\"services.gemini_client.genai.Client\")\n    @patch(\"builtins.open\", new_callable=mock_open, read_data=b\"fake audio data\")\n    def test_analyze_audio_with_retry_503(self, mock_file, mock_genai_client, sample_audio_file):\n        \"\"\"\u6d4b\u8bd5 503 \u9519\u8bef\u91cd\u8bd5\u673a\u5236\"\"\"\n        mock_client_instance = Mock()\n        mock_genai_client.return_value = mock_client_instance\n    \n        # \u7b2c\u4e00\u6b21\u8c03\u7528\u5931\u8d25\uff0c\u7b2c\u4e8c\u6b21\u6210\u529f\n        mock_response_1 = Mock(side_effect=Exception(\"503 Service Unavailable\"))\n        mock_response_2 = Mock()\n        mock_response_2.text = \"\u91cd\u8bd5\u540e\u6210\u529f\"\n    \n        mock_client_instance.models.generate_content.side_effect = [\n            mock_response_1,\n            mock_response_2\n        ]\n    \n        client = GeminiClient()\n    \n        # Patch time.sleep to avoid actual delay\n>       with patch(\"services.gemini_client.time.sleep\"):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests/test_gemini_client.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.gemini_client.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.gemini_client' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 9.462499997425766e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_max_retries_exceeded", "lineno": 92, "outcome": "failed", "keywords": ["test_analyze_audio_max_retries_exceeded", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0004720830000906062, "outcome": "passed"}, "call": {"duration": 8.391599999413302e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.gemini_client' has no attribute 'time'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_gemini_client.TestAnalyzeAudioFromPath object at 0x126449220>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_analyze_audio_max_retries0/test_audio.webm'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.gemini_client.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.gemini_client' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 0.00010829200004991435, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_non_retryable_error", "lineno": 111, "outcome": "passed", "keywords": ["test_analyze_audio_non_retryable_error", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00047904099994866556, "outcome": "passed"}, "call": {"duration": 0.001058209000007082, "outcome": "passed", "stdout": "\ud83d\udcca \u5c1d\u8bd5 1/3: \u97f3\u9891\u5927\u5c0f 0.0KB\n"}, "teardown": {"duration": 6.212499999946886e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_retry_with_exponential_backoff", "lineno": 130, "outcome": "failed", "keywords": ["test_retry_with_exponential_backoff", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0005197499999667343, "outcome": "passed"}, "call": {"duration": 9.21670000479935e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.gemini_client' has no attribute 'time'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_gemini_client.TestAnalyzeAudioFromPath object at 0x1262fa330>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_retry_with_exponential_ba0/test_audio.webm'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.gemini_client.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.gemini_client' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 0.00011716599999544997, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_ssl_error_retry", "lineno": 154, "outcome": "failed", "keywords": ["test_analyze_audio_ssl_error_retry", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00045212500003799505, "outcome": "passed"}, "call": {"duration": 0.0006582089999938034, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.gemini_client' has no attribute 'time'"}, "traceback": [{"path": "tests/test_gemini_client.py", "lineno": 173, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "self = <tests.test_gemini_client.TestAnalyzeAudioFromPath object at 0x1264029c0>\nmock_file = <MagicMock name='open' id='4940094432'>\nmock_genai_client = <MagicMock name='Client' id='4940089392'>\nsample_audio_file = '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_analyze_audio_ssl_error_r0/test_audio.webm'\n\n    @patch(\"services.gemini_client.genai.Client\")\n    @patch(\"builtins.open\", new_callable=mock_open, read_data=b\"fake audio data\")\n    def test_analyze_audio_ssl_error_retry(self, mock_file, mock_genai_client, sample_audio_file):\n        \"\"\"\u6d4b\u8bd5 SSL \u9519\u8bef\u91cd\u8bd5\"\"\"\n        mock_client_instance = Mock()\n        mock_genai_client.return_value = mock_client_instance\n    \n        mock_response_1 = Mock(side_effect=Exception(\"SSL error\"))\n        mock_response_2 = Mock()\n        mock_response_2.text = \"\u91cd\u8bd5\u6210\u529f\"\n    \n        mock_client_instance.models.generate_content.side_effect = [\n            mock_response_1,\n            mock_response_2\n        ]\n    \n        client = GeminiClient()\n    \n>       with patch(\"services.gemini_client.time.sleep\"):\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests/test_gemini_client.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.gemini_client.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.gemini_client' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 0.00011454100001628831, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_retryable_connection_errors", "lineno": 178, "outcome": "failed", "keywords": ["test_retryable_connection_errors", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0004757499999641368, "outcome": "passed"}, "call": {"duration": 9.191699996335956e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.gemini_client' has no attribute 'time'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_gemini_client.TestAnalyzeAudioFromPath object at 0x126402cf0>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_retryable_connection_erro0/test_audio.webm'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.gemini_client.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.gemini_client' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 0.00010112500001469016, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAnalyzeAudioFromPath::test_analyze_audio_file_not_found", "lineno": 205, "outcome": "failed", "keywords": ["test_analyze_audio_file_not_found", "__wrapped__", "patchings", "TestAnalyzeAudioFromPath", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00046179100002063933, "outcome": "passed"}, "call": {"duration": 0.00021775000004709, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/services/gemini_client.py", "lineno": 97, "message": "Exception: \u274c \u5206\u6790\u5931\u8d25: [Errno 2] No such file or directory: '/nonexistent/file.webm'"}, "traceback": [{"path": "tests/test_gemini_client.py", "lineno": 215, "message": ""}, {"path": "services/gemini_client.py", "lineno": 97, "message": "Exception"}], "longrepr": "self = <services.gemini_client.GeminiClient object at 0x126755480>\naudio_path = '/nonexistent/file.webm', prompt = '\u5206\u6790\u8fd9\u4e2a\u97f3\u9891'\n\n    def analyze_audio_from_path(self, audio_path: str, prompt: str):\n        \"\"\"\n        \u76f4\u63a5\u4ece\u6587\u4ef6\u8def\u5f84\u5206\u6790\u97f3\u9891\n    \n        \u6839\u636e\u5b98\u65b9\u6587\u6863: https://ai.google.dev/gemini-api/docs/audio\n        \u4f7f\u7528\u5185\u5d4c\u97f3\u9891\u6570\u636e\u65b9\u6cd5\uff08\u9002\u7528\u4e8e\u5c0f\u4e8e 20MB \u7684\u6587\u4ef6\uff09\n    \n        \u652f\u6301\u81ea\u52a8\u91cd\u8bd5\u673a\u5236\u5904\u7406 503 \u670d\u52a1\u8fc7\u8f7d\u9519\u8bef\n    \n        Args:\n            audio_path: \u97f3\u9891\u6587\u4ef6\u8def\u5f84\n            prompt: \u5206\u6790\u63d0\u793a\u8bcd\n    \n        Returns:\n            Gemini \u7684\u54cd\u5e94\u5185\u5bb9\n        \"\"\"\n        import time\n    \n        max_retries = 3\n        retry_delay = 2  # \u521d\u59cb\u5ef6\u8fdf\uff08\u79d2\uff09\n    \n        for attempt in range(max_retries):\n            try:\n                # \u8bfb\u53d6\u97f3\u9891\u6587\u4ef6\n>               with open(audio_path, 'rb') as f:\n                     ^^^^^^^^^^^^^^^^^^^^^^\nE               FileNotFoundError: [Errno 2] No such file or directory: '/nonexistent/file.webm'\n\nservices/gemini_client.py:53: FileNotFoundError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <tests.test_gemini_client.TestAnalyzeAudioFromPath object at 0x12642b850>\nmock_genai_client = <MagicMock name='Client' id='4940095776'>\nsample_audio_file = '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_analyze_audio_file_not_fo0/test_audio.webm'\n\n    @patch(\"services.gemini_client.genai.Client\")\n    def test_analyze_audio_file_not_found(self, mock_genai_client, sample_audio_file):\n        \"\"\"\u6d4b\u8bd5\u6587\u4ef6\u4e0d\u5b58\u5728\"\"\"\n        mock_client_instance = Mock()\n        mock_genai_client.return_value = mock_client_instance\n    \n        client = GeminiClient()\n    \n        with pytest.raises(FileNotFoundError):\n>           client.analyze_audio_from_path(\"/nonexistent/file.webm\", \"\u5206\u6790\u8fd9\u4e2a\u97f3\u9891\")\n\ntests/test_gemini_client.py:215: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <services.gemini_client.GeminiClient object at 0x126755480>\naudio_path = '/nonexistent/file.webm', prompt = '\u5206\u6790\u8fd9\u4e2a\u97f3\u9891'\n\n    def analyze_audio_from_path(self, audio_path: str, prompt: str):\n        \"\"\"\n        \u76f4\u63a5\u4ece\u6587\u4ef6\u8def\u5f84\u5206\u6790\u97f3\u9891\n    \n        \u6839\u636e\u5b98\u65b9\u6587\u6863: https://ai.google.dev/gemini-api/docs/audio\n        \u4f7f\u7528\u5185\u5d4c\u97f3\u9891\u6570\u636e\u65b9\u6cd5\uff08\u9002\u7528\u4e8e\u5c0f\u4e8e 20MB \u7684\u6587\u4ef6\uff09\n    \n        \u652f\u6301\u81ea\u52a8\u91cd\u8bd5\u673a\u5236\u5904\u7406 503 \u670d\u52a1\u8fc7\u8f7d\u9519\u8bef\n    \n        Args:\n            audio_path: \u97f3\u9891\u6587\u4ef6\u8def\u5f84\n            prompt: \u5206\u6790\u63d0\u793a\u8bcd\n    \n        Returns:\n            Gemini \u7684\u54cd\u5e94\u5185\u5bb9\n        \"\"\"\n        import time\n    \n        max_retries = 3\n        retry_delay = 2  # \u521d\u59cb\u5ef6\u8fdf\uff08\u79d2\uff09\n    \n        for attempt in range(max_retries):\n            try:\n                # \u8bfb\u53d6\u97f3\u9891\u6587\u4ef6\n                with open(audio_path, 'rb') as f:\n                    audio_bytes = f.read()\n    \n                print(f\"\ud83d\udcca \u5c1d\u8bd5 {attempt + 1}/{max_retries}: \u97f3\u9891\u5927\u5c0f {len(audio_bytes)/1024:.1f}KB\")\n    \n                # \u4f7f\u7528\u65b0 SDK \u7684 API - \u5185\u5d4c\u97f3\u9891\u6570\u636e\n                # \u6839\u636e\u5b98\u65b9\u6587\u6863\u793a\u4f8b\n                response = self.client.models.generate_content(\n                    model=MODEL_NAME,\n                    contents=[\n                        prompt,\n                        types.Part.from_bytes(\n                            data=audio_bytes,\n                            mime_type='audio/webm'\n                        )\n                    ]\n                )\n    \n                return response.text\n    \n            except Exception as e:\n                error_str = str(e)\n    \n                # \u68c0\u67e5\u662f\u5426\u662f\u53ef\u91cd\u8bd5\u7684\u9519\u8bef\n                is_retryable = (\n                    '503' in error_str or\n                    'overloaded' in error_str.lower() or\n                    'SSL' in error_str or\n                    'EOF' in error_str or\n                    'Connection' in error_str or\n                    'timeout' in error_str.lower() or\n                    'reset' in error_str.lower()\n                )\n    \n                if is_retryable:\n                    if attempt < max_retries - 1:\n                        wait_time = retry_delay * (2 ** attempt)  # \u6307\u6570\u9000\u907f\n                        print(f\"\u23f3 \u7f51\u7edc/API\u9519\u8bef\uff0c{wait_time}\u79d2\u540e\u91cd\u8bd5... (\u9519\u8bef: {error_str[:50]})\")\n                        time.sleep(wait_time)\n                        continue\n                    else:\n                        raise Exception(f\"\u274c \u7f51\u7edc\u8fde\u63a5\u95ee\u9898\uff0c\u5df2\u91cd\u8bd5{max_retries}\u6b21\u3002\u8bf7\u68c0\u67e5\u7f51\u7edc/VPN\u540e\u518d\u8bd5\u3002\")\n                else:\n                    # \u5176\u4ed6\u9519\u8bef\u76f4\u63a5\u629b\u51fa\n>                   raise Exception(f\"\u274c \u5206\u6790\u5931\u8d25: {error_str}\")\nE                   Exception: \u274c \u5206\u6790\u5931\u8d25: [Errno 2] No such file or directory: '/nonexistent/file.webm'\n\nservices/gemini_client.py:97: Exception"}, "teardown": {"duration": 0.00010583400000996335, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio::test_upload_and_analyze_success", "lineno": 220, "outcome": "passed", "keywords": ["test_upload_and_analyze_success", "__wrapped__", "patchings", "TestUploadAndAnalyzeAudio", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0005035420000467639, "outcome": "passed"}, "call": {"duration": 0.0003097909999496551, "outcome": "passed", "stdout": "Uploading audio file: /private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_upload_and_analyze_succes0/test_audio.webm\nFile uploaded: uploaded-file-uri\n"}, "teardown": {"duration": 4.783400004271243e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio::test_upload_and_analyze_upload_failure", "lineno": 243, "outcome": "passed", "keywords": ["test_upload_and_analyze_upload_failure", "__wrapped__", "patchings", "TestUploadAndAnalyzeAudio", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00034820899998067034, "outcome": "passed"}, "call": {"duration": 0.00019241699999383854, "outcome": "passed", "stdout": "Uploading audio file: /private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_upload_and_analyze_upload0/test_audio.webm\n"}, "teardown": {"duration": 4.3624999989333446e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestUploadAndAnalyzeAudio::test_upload_and_analyze_generation_failure", "lineno": 258, "outcome": "passed", "keywords": ["test_upload_and_analyze_generation_failure", "__wrapped__", "patchings", "TestUploadAndAnalyzeAudio", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00046254200003659207, "outcome": "passed"}, "call": {"duration": 0.0002092080000011265, "outcome": "passed", "stdout": "Uploading audio file: /private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_upload_and_analyze_genera0/test_audio.webm\nFile uploaded: uploaded-file-uri\n"}, "teardown": {"duration": 4.5915999976386956e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestModuleConstants::test_model_name", "lineno": 283, "outcome": "passed", "keywords": ["test_model_name", "TestModuleConstants", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 4.112500005248876e-05, "outcome": "passed"}, "call": {"duration": 4.333399999723042e-05, "outcome": "passed"}, "teardown": {"duration": 3.404200003842561e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestModuleConstants::test_gemini_api_key_exists", "lineno": 287, "outcome": "failed", "keywords": ["test_gemini_api_key_exists", "TestModuleConstants", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 3.762500000448199e-05, "outcome": "passed"}, "call": {"duration": 0.00010529100006806402, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/tests/test_gemini_client.py", "lineno": 291, "message": "AssertionError: assert 'GEMINI_API_KEY' in ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', ...]\n +  where ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', ...] = dir('services.gemini_client')"}, "traceback": [{"path": "tests/test_gemini_client.py", "lineno": 291, "message": "AssertionError"}], "longrepr": "self = <tests.test_gemini_client.TestModuleConstants object at 0x126463c50>\n\n    def test_gemini_api_key_exists(self):\n        \"\"\"\u6d4b\u8bd5 API KEY \u5b58\u5728\"\"\"\n        # \u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u53ef\u80fd\u6ca1\u6709\u8bbe\u7f6e\uff0c\u6240\u4ee5\u53ea\u9a8c\u8bc1\u53d8\u91cf\u5b58\u5728\n>       assert \"GEMINI_API_KEY\" in dir(\"services.gemini_client\")\nE       AssertionError: assert 'GEMINI_API_KEY' in ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', ...]\nE        +  where ['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', ...] = dir('services.gemini_client')\n\ntests/test_gemini_client.py:291: AssertionError"}, "teardown": {"duration": 4.041600004711654e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestGlobalGeminiClient::test_global_client_exists", "lineno": 296, "outcome": "passed", "keywords": ["test_global_client_exists", "__wrapped__", "patchings", "TestGlobalGeminiClient", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 4.1333000012855337e-05, "outcome": "passed"}, "call": {"duration": 0.00010987500002102024, "outcome": "passed"}, "teardown": {"duration": 3.679200005990424e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAudioFileHandling::test_reads_audio_file_correctly", "lineno": 307, "outcome": "passed", "keywords": ["test_reads_audio_file_correctly", "__wrapped__", "patchings", "TestAudioFileHandling", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0003592079999634734, "outcome": "passed"}, "call": {"duration": 0.0007350410000981356, "outcome": "passed", "stdout": "\ud83d\udcca \u5c1d\u8bd5 1/3: \u97f3\u9891\u5927\u5c0f 0.0KB\n"}, "teardown": {"duration": 4.295799999454175e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestAudioFileHandling::test_logs_audio_file_size", "lineno": 321, "outcome": "passed", "keywords": ["test_logs_audio_file_size", "__wrapped__", "patchings", "TestAudioFileHandling", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.00033691700002691505, "outcome": "passed"}, "call": {"duration": 0.000870666000082565, "outcome": "passed"}, "teardown": {"duration": 4.437500001586159e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_client.py::TestContentType::test_uses_correct_mime_type", "lineno": 341, "outcome": "passed", "keywords": ["test_uses_correct_mime_type", "__wrapped__", "patchings", "TestContentType", "test_gemini_client.py", "tests", "server", ""], "setup": {"duration": 0.0003582919999871592, "outcome": "passed"}, "call": {"duration": 0.0007581669999581209, "outcome": "passed", "stdout": "\ud83d\udcca \u5c1d\u8bd5 1/3: \u97f3\u9891\u5927\u5c0f 0.0KB\n"}, "teardown": {"duration": 5.370799999582232e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_five_stars", "lineno": 17, "outcome": "passed", "keywords": ["test_five_stars", "TestCalculateStarRating", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 4.3000000005122274e-05, "outcome": "passed"}, "call": {"duration": 4.766699998981494e-05, "outcome": "passed"}, "teardown": {"duration": 3.662500000700675e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_four_stars", "lineno": 22, "outcome": "passed", "keywords": ["test_four_stars", "TestCalculateStarRating", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 4.391699997086107e-05, "outcome": "passed"}, "call": {"duration": 4.5666000005439855e-05, "outcome": "passed"}, "teardown": {"duration": 3.545799995663401e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_three_stars", "lineno": 27, "outcome": "passed", "keywords": ["test_three_stars", "TestCalculateStarRating", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 4.087500008154166e-05, "outcome": "passed"}, "call": {"duration": 4.354200007128384e-05, "outcome": "passed"}, "teardown": {"duration": 3.4083000059581536e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_two_stars", "lineno": 32, "outcome": "passed", "keywords": ["test_two_stars", "TestCalculateStarRating", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.7416999930428574e-05, "outcome": "passed"}, "call": {"duration": 4.1915999986485986e-05, "outcome": "passed"}, "teardown": {"duration": 3.274999994573591e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestCalculateStarRating::test_one_star", "lineno": 37, "outcome": "passed", "keywords": ["test_one_star", "TestCalculateStarRating", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.666700001758727e-05, "outcome": "passed"}, "call": {"duration": 4.0125000055013516e-05, "outcome": "passed"}, "teardown": {"duration": 3.2000000032894604e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation::test_create_part1_prompt", "lineno": 45, "outcome": "passed", "keywords": ["test_create_part1_prompt", "TestPromptCreation", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.6832999967373325e-05, "outcome": "passed"}, "call": {"duration": 4.416700005549501e-05, "outcome": "passed"}, "teardown": {"duration": 3.0834000085633306e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation::test_create_part2_prompt", "lineno": 57, "outcome": "passed", "keywords": ["test_create_part2_prompt", "TestPromptCreation", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.6582999996426224e-05, "outcome": "passed"}, "call": {"duration": 4.829199997402611e-05, "outcome": "passed"}, "teardown": {"duration": 3.2375000046158675e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestPromptCreation::test_create_part3_prompt", "lineno": 69, "outcome": "passed", "keywords": ["test_create_part3_prompt", "TestPromptCreation", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.591699999105913e-05, "outcome": "passed"}, "call": {"duration": 4.404200001317804e-05, "outcome": "passed"}, "teardown": {"duration": 3.249999997478881e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_clean_json", "lineno": 86, "outcome": "passed", "keywords": ["test_parse_clean_json", "TestParseGeminiResponse", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.6375000036059646e-05, "outcome": "passed"}, "call": {"duration": 0.0001359589999765376, "outcome": "passed", "stdout": "\u2705 \u8bc4\u5206\u5b8c\u6210: 10 \u5206\n"}, "teardown": {"duration": 3.249999997478881e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_json_in_code_block", "lineno": 95, "outcome": "passed", "keywords": ["test_parse_json_in_code_block", "TestParseGeminiResponse", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.795899999659014e-05, "outcome": "passed"}, "call": {"duration": 6.533299995226116e-05, "outcome": "passed", "stdout": "\u2705 \u8bc4\u5206\u5b8c\u6210: 8 \u5206\n"}, "teardown": {"duration": 3.233400002500275e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_json_with_trailing_comma", "lineno": 104, "outcome": "passed", "keywords": ["test_parse_json_with_trailing_comma", "TestParseGeminiResponse", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 3.616699996200623e-05, "outcome": "passed"}, "call": {"duration": 0.0008037499999318243, "outcome": "passed", "stdout": "\u2705 \u8bc4\u5206\u5b8c\u6210: 10 \u5206\n"}, "teardown": {"duration": 3.854099998079619e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_invalid_json_raises_error", "lineno": 111, "outcome": "passed", "keywords": ["test_parse_invalid_json_raises_error", "TestParseGeminiResponse", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 7.204200005617167e-05, "outcome": "passed"}, "call": {"duration": 0.00011129099993922864, "outcome": "passed", "stdout": "\u274c JSON\u89e3\u6790\u5931\u8d25: Expecting value: line 1 column 1 (char 0)\n\u54cd\u5e94\u5185\u5bb9: not a json...\n"}, "teardown": {"duration": 4.2042000018227554e-05, "outcome": "passed"}}, {"nodeid": "tests/test_gemini_scorer.py::TestParseGeminiResponse::test_parse_questions_format", "lineno": 116, "outcome": "passed", "keywords": ["test_parse_questions_format", "TestParseGeminiResponse", "test_gemini_scorer.py", "tests", "server", ""], "setup": {"duration": 5.804199997783144e-05, "outcome": "passed"}, "call": {"duration": 9.96669999722144e-05, "outcome": "passed", "stdout": "\u2705 \u5206\u7ec4\u8bc4\u5206\u5b8c\u6210: 3 \u5206 (2\u4e2a\u95ee\u9898)\n"}, "teardown": {"duration": 4.283299995222478e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_success", "lineno": 52, "outcome": "passed", "keywords": ["test_evaluate_single_question_success", "__wrapped__", "patchings", "TestEvaluatePart3SingleQuestion", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.00046120899992274644, "outcome": "passed"}, "call": {"duration": 0.00022462499998709973, "outcome": "passed"}, "teardown": {"duration": 5.27500000089276e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_partial_score", "lineno": 71, "outcome": "passed", "keywords": ["test_evaluate_single_question_partial_score", "__wrapped__", "patchings", "TestEvaluatePart3SingleQuestion", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.00043795900000986876, "outcome": "passed"}, "call": {"duration": 0.00018741700000646233, "outcome": "passed"}, "teardown": {"duration": 5.0542000053610536e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_zero_score", "lineno": 87, "outcome": "passed", "keywords": ["test_evaluate_single_question_zero_score", "__wrapped__", "patchings", "TestEvaluatePart3SingleQuestion", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003840419999505684, "outcome": "passed"}, "call": {"duration": 0.0001668329999802154, "outcome": "passed"}, "teardown": {"duration": 5.025000007208291e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_with_additional_scores", "lineno": 103, "outcome": "passed", "keywords": ["test_evaluate_with_additional_scores", "__wrapped__", "patchings", "TestEvaluatePart3SingleQuestion", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003533330000209389, "outcome": "passed"}, "call": {"duration": 0.00016433299992968387, "outcome": "passed"}, "teardown": {"duration": 4.987500005881884e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3SingleQuestion::test_evaluate_single_question_missing_score", "lineno": 127, "outcome": "passed", "keywords": ["test_evaluate_single_question_missing_score", "__wrapped__", "patchings", "TestEvaluatePart3SingleQuestion", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003682079999407506, "outcome": "passed"}, "call": {"duration": 0.00015824999991309596, "outcome": "passed"}, "teardown": {"duration": 5.445800002235046e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_six_questions", "lineno": 147, "outcome": "passed", "keywords": ["test_evaluate_group_six_questions", "__wrapped__", "patchings", "TestEvaluatePart3Group", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.00035183299996788264, "outcome": "passed"}, "call": {"duration": 0.00016941600006248336, "outcome": "passed"}, "teardown": {"duration": 4.987500005881884e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_with_start_question_7", "lineno": 177, "outcome": "passed", "keywords": ["test_evaluate_group_with_start_question_7", "__wrapped__", "patchings", "TestEvaluatePart3Group", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.00034808399993835337, "outcome": "passed"}, "call": {"duration": 0.00016529100003026542, "outcome": "passed"}, "teardown": {"duration": 4.9208000064027146e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_incomplete_results", "lineno": 203, "outcome": "passed", "keywords": ["test_evaluate_group_incomplete_results", "__wrapped__", "patchings", "TestEvaluatePart3Group", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.000347250000004351, "outcome": "passed"}, "call": {"duration": 0.001511707999952705, "outcome": "passed"}, "teardown": {"duration": 5.870799998319853e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_overall_scores_added", "lineno": 238, "outcome": "passed", "keywords": ["test_evaluate_group_overall_scores_added", "__wrapped__", "patchings", "TestEvaluatePart3Group", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0004542909999827316, "outcome": "passed"}, "call": {"duration": 0.00018591699995340605, "outcome": "passed"}, "teardown": {"duration": 4.52500000847067e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart3Group::test_evaluate_group_default_overall_scores", "lineno": 265, "outcome": "passed", "keywords": ["test_evaluate_group_default_overall_scores", "__wrapped__", "patchings", "TestEvaluatePart3Group", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003517499999361462, "outcome": "passed"}, "call": {"duration": 0.00016266600005110377, "outcome": "passed"}, "teardown": {"duration": 4.404200001317804e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_twelve_questions", "lineno": 294, "outcome": "passed", "keywords": ["test_evaluate_part2_twelve_questions", "__wrapped__", "patchings", "TestEvaluatePart2All", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003525829999944108, "outcome": "passed"}, "call": {"duration": 0.00017012499995416874, "outcome": "passed"}, "teardown": {"duration": 4.345900003954739e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_incomplete_results", "lineno": 321, "outcome": "passed", "keywords": ["test_evaluate_part2_incomplete_results", "__wrapped__", "patchings", "TestEvaluatePart2All", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0005187919999798396, "outcome": "passed"}, "call": {"duration": 0.00016941700005190796, "outcome": "passed"}, "teardown": {"duration": 4.358299997875292e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_returns_overall_scores", "lineno": 352, "outcome": "passed", "keywords": ["test_evaluate_part2_returns_overall_scores", "__wrapped__", "patchings", "TestEvaluatePart2All", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003445419999934529, "outcome": "passed"}, "call": {"duration": 0.00016445799997200083, "outcome": "passed"}, "teardown": {"duration": 4.595899997639208e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEvaluatePart2All::test_evaluate_part2_mixed_scores", "lineno": 378, "outcome": "passed", "keywords": ["test_evaluate_part2_mixed_scores", "__wrapped__", "patchings", "TestEvaluatePart2All", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.00035291699998651893, "outcome": "passed"}, "call": {"duration": 0.0001634170000670565, "outcome": "passed"}, "teardown": {"duration": 4.3125000047439244e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration::test_single_question_prompt_contains_question_num", "lineno": 406, "outcome": "passed", "keywords": ["test_single_question_prompt_contains_question_num", "__wrapped__", "patchings", "TestPromptGeneration", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003501669999650403, "outcome": "passed"}, "call": {"duration": 0.00015887500001099397, "outcome": "passed"}, "teardown": {"duration": 4.3375000018386345e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration::test_group_prompt_contains_all_questions", "lineno": 423, "outcome": "passed", "keywords": ["test_group_prompt_contains_all_questions", "__wrapped__", "patchings", "TestPromptGeneration", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.00034537499993803067, "outcome": "passed"}, "call": {"duration": 0.011946375000093212, "outcome": "passed"}, "teardown": {"duration": 6.866599994737044e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestPromptGeneration::test_part2_prompt_contains_twelve_questions", "lineno": 449, "outcome": "passed", "keywords": ["test_part2_prompt_contains_twelve_questions", "__wrapped__", "patchings", "TestPromptGeneration", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0005442079999511407, "outcome": "passed"}, "call": {"duration": 0.000297291000038058, "outcome": "passed"}, "teardown": {"duration": 6.170799997562426e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestRetryBehavior::test_single_question_retry_on_failure", "lineno": 479, "outcome": "failed", "keywords": ["test_single_question_retry_on_failure", "__wrapped__", "patchings", "TestRetryBehavior", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0004736660000617121, "outcome": "passed"}, "call": {"duration": 0.00011670899993987405, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.part3_evaluator' has no attribute 'time'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_part3_evaluator.TestRetryBehavior object at 0x1264e5bd0>,)\nkeywargs = {'mock_audio_path': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_single_q...{'student_options': ['I like pizza', 'I love sushi', 'My favorite is pasta'], 'teacher': \"What's your favorite food?\"}}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.part3_evaluator.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.part3_evaluator' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 0.00010362500006522168, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestRetryBehavior::test_group_retry_on_failure", "lineno": 500, "outcome": "failed", "keywords": ["test_group_retry_on_failure", "__wrapped__", "patchings", "TestRetryBehavior", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0005032089999303935, "outcome": "passed"}, "call": {"duration": 8.800000000519503e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError: module 'services.part3_evaluator' has no attribute 'time'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1487, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py", "lineno": 473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_part3_evaluator.TestRetryBehavior object at 0x1264e5d10>,)\nkeywargs = {'mock_audio_path': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_group_re...5A', 'Answer 5B'], 'teacher': 'Question 5'}, {'student_options': ['Answer 6A', 'Answer 6B'], 'teacher': 'Question 6'}]}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1487: in __enter__\n    self.target = self.getter()\n                  ^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nname = 'services.part3_evaluator.time'\n\n    def resolve_name(name):\n        \"\"\"\n        Resolve a name to an object.\n    \n        It is expected that `name` will be a string in one of the following\n        formats, where W is shorthand for a valid Python identifier and dot stands\n        for a literal period in these pseudo-regexes:\n    \n        W(.W)*\n        W(.W)*:(W(.W)*)?\n    \n        The first form is intended for backward compatibility only. It assumes that\n        some part of the dotted name is a package, and the rest is an object\n        somewhere within that package, possibly nested inside other objects.\n        Because the place where the package stops and the object hierarchy starts\n        can't be inferred by inspection, repeated attempts to import must be done\n        with this form.\n    \n        In the second form, the caller makes the division point clear through the\n        provision of a single colon: the dotted name to the left of the colon is a\n        package to be imported, and the dotted name to the right is the object\n        hierarchy within that package. Only one import is needed in this form. If\n        it ends with the colon, then a module object is returned.\n    \n        The function will return an object (which might be a module), or raise one\n        of the following exceptions:\n    \n        ValueError - if `name` isn't in a recognised format\n        ImportError - if an import failed when it shouldn't have\n        AttributeError - if a failure occurred when traversing the object hierarchy\n                         within the imported package to get to the desired object.\n        \"\"\"\n        global _NAME_PATTERN\n        if _NAME_PATTERN is None:\n            # Lazy import to speedup Python startup time\n            import re\n            dotted_words = r'(?!\\d)(\\w+)(\\.(?!\\d)(\\w+))*'\n            _NAME_PATTERN = re.compile(f'^(?P<pkg>{dotted_words})'\n                                       f'(?P<cln>:(?P<obj>{dotted_words})?)?$',\n                                       re.UNICODE)\n    \n        m = _NAME_PATTERN.match(name)\n        if not m:\n            raise ValueError(f'invalid format: {name!r}')\n        gd = m.groupdict()\n        if gd.get('cln'):\n            # there is a colon - a one-step import is all that's needed\n            mod = importlib.import_module(gd['pkg'])\n            parts = gd.get('obj')\n            parts = parts.split('.') if parts else []\n        else:\n            # no colon - have to iterate to find the package boundary\n            parts = name.split('.')\n            modname = parts.pop(0)\n            # first part *must* be a module/package.\n            mod = importlib.import_module(modname)\n            while parts:\n                p = parts[0]\n                s = f'{modname}.{p}'\n                try:\n                    mod = importlib.import_module(s)\n                    parts.pop(0)\n                    modname = s\n                except ImportError:\n                    break\n        # if we reach this point, mod is the module, already imported, and\n        # parts is the list of parts in the object hierarchy to be traversed, or\n        # an empty list if just the module is wanted.\n        result = mod\n        for p in parts:\n>           result = getattr(result, p)\n                     ^^^^^^^^^^^^^^^^^^\nE           AttributeError: module 'services.part3_evaluator' has no attribute 'time'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/pkgutil.py:473: AttributeError"}, "teardown": {"duration": 0.00010879100000238395, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEdgeCases::test_empty_dialogue_student_options", "lineno": 531, "outcome": "passed", "keywords": ["test_empty_dialogue_student_options", "__wrapped__", "patchings", "TestEdgeCases", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.000503457999911916, "outcome": "passed"}, "call": {"duration": 0.00024991700001919526, "outcome": "passed"}, "teardown": {"duration": 4.8708000008446106e-05, "outcome": "passed"}}, {"nodeid": "tests/test_part3_evaluator.py::TestEdgeCases::test_dialogue_missing_student_options", "lineno": 550, "outcome": "passed", "keywords": ["test_dialogue_missing_student_options", "__wrapped__", "patchings", "TestEdgeCases", "test_part3_evaluator.py", "tests", "server", ""], "setup": {"duration": 0.0003893330000437345, "outcome": "passed"}, "call": {"duration": 0.0001810420000083468, "outcome": "passed"}, "teardown": {"duration": 4.82090000559765e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_success_no_retry", "lineno": 12, "outcome": "passed", "keywords": ["test_success_no_retry", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 4.6417000021392596e-05, "outcome": "passed"}, "call": {"duration": 4.995899996629305e-05, "outcome": "passed"}, "teardown": {"duration": 3.787500008911593e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_retry_then_success", "lineno": 26, "outcome": "passed", "keywords": ["test_retry_then_success", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 4.4083000034333963e-05, "outcome": "passed"}, "call": {"duration": 0.105243499999915, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/4): Temporary error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n"}, "teardown": {"duration": 7.154100001116603e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_max_retries_exceeded", "lineno": 42, "outcome": "passed", "keywords": ["test_max_retries_exceeded", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 6.891700002142898e-05, "outcome": "passed"}, "call": {"duration": 0.2100312090000216, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Persistent error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/3): Persistent error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/3): Persistent error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 0.00010374999999385182, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_exponential_backoff", "lineno": 58, "outcome": "passed", "keywords": ["test_exponential_backoff", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 8.370800003376644e-05, "outcome": "passed"}, "call": {"duration": 0.00045258299996930873, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/4): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n"}, "teardown": {"duration": 6.325000003926107e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_multiple_retries_with_backoff", "lineno": 77, "outcome": "passed", "keywords": ["test_multiple_retries_with_backoff", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00011512499997934356, "outcome": "passed"}, "call": {"duration": 0.0004840829999466223, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/4): Always fails\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/4): Always fails\n   \u7b49\u5f85 0.2 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/4): Always fails\n   \u7b49\u5f85 0.4 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 4/4): Always fails\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 6.9208000013532e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_location_error_message", "lineno": 96, "outcome": "passed", "keywords": ["test_location_error_message", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 7.133400004022405e-05, "outcome": "passed"}, "call": {"duration": 0.1054916250000133, "outcome": "passed"}, "teardown": {"duration": 0.00012104199993245857, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_general_error_message", "lineno": 115, "outcome": "passed", "keywords": ["test_general_error_message", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00011616699998739932, "outcome": "passed"}, "call": {"duration": 0.10575441700007104, "outcome": "passed"}, "teardown": {"duration": 0.00014416700003039296, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_default_parameters", "lineno": 129, "outcome": "passed", "keywords": ["test_default_parameters", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00012220800010709354, "outcome": "passed"}, "call": {"duration": 0.0001417920000221784, "outcome": "passed"}, "teardown": {"duration": 8.283299996492133e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_custom_max_retries", "lineno": 138, "outcome": "passed", "keywords": ["test_custom_max_retries", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.629100009078684e-05, "outcome": "passed"}, "call": {"duration": 0.30829770900004405, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/6): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/6): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/6): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n"}, "teardown": {"duration": 0.00011700000004566391, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_custom_delay", "lineno": 154, "outcome": "passed", "keywords": ["test_custom_delay", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.704199999305274e-05, "outcome": "passed"}, "call": {"duration": 0.0010797920000413797, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/2): Error\n   \u7b49\u5f85 0.5 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/2): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 6.941599997389858e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_custom_backoff", "lineno": 167, "outcome": "passed", "keywords": ["test_custom_backoff", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 7.345899996380467e-05, "outcome": "passed"}, "call": {"duration": 0.0003467500000624568, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Error\n   \u7b49\u5f85 1.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/3): Error\n   \u7b49\u5f85 3.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/3): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 5.2665999987766554e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_function_with_arguments", "lineno": 185, "outcome": "passed", "keywords": ["test_function_with_arguments", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 6.65000000026339e-05, "outcome": "passed"}, "call": {"duration": 7.291700001132995e-05, "outcome": "passed"}, "teardown": {"duration": 5.058299996107962e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_function_with_arguments_retry", "lineno": 197, "outcome": "passed", "keywords": ["test_function_with_arguments_retry", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 5.716599991956173e-05, "outcome": "passed"}, "call": {"duration": 0.10537137500000426, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Error with test\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n"}, "teardown": {"duration": 0.00012020799999845622, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_different_exception_types", "lineno": 213, "outcome": "passed", "keywords": ["test_different_exception_types", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00010883400000238908, "outcome": "passed"}, "call": {"duration": 0.10151616699999977, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/2): Value error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/2): Value error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 0.00015029199994387454, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_zero_retries", "lineno": 224, "outcome": "passed", "keywords": ["test_zero_retries", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00012925000010000076, "outcome": "passed"}, "call": {"duration": 0.0005717500000628206, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/1): No retry\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 9.612500002731394e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_function_returns_none", "lineno": 237, "outcome": "passed", "keywords": ["test_function_returns_none", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00010562499994648533, "outcome": "passed"}, "call": {"duration": 0.10558979099994303, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n"}, "teardown": {"duration": 0.0002234170000292579, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_preserves_function_name", "lineno": 253, "outcome": "passed", "keywords": ["test_preserves_function_name", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.0002646670000103768, "outcome": "passed"}, "call": {"duration": 0.0001490419999754522, "outcome": "passed"}, "teardown": {"duration": 7.158400001117116e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_preserves_function_docstring", "lineno": 261, "outcome": "passed", "keywords": ["test_preserves_function_docstring", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 6.929200003469305e-05, "outcome": "passed"}, "call": {"duration": 7.000000005064066e-05, "outcome": "passed"}, "teardown": {"duration": 5.312500002219167e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_consecutive_successes", "lineno": 270, "outcome": "passed", "keywords": ["test_consecutive_successes", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00011987499999577267, "outcome": "passed"}, "call": {"duration": 0.00013449999994463724, "outcome": "passed"}, "teardown": {"duration": 9.145800004262128e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnError::test_long_delay_between_retries", "lineno": 281, "outcome": "passed", "keywords": ["test_long_delay_between_retries", "TestRetryOnError", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00010833299995738344, "outcome": "passed"}, "call": {"duration": 0.0006832090000443714, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/2): Error\n   \u7b49\u5f85 10.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/2): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 8.404199991218775e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_negative_delay", "lineno": 297, "outcome": "passed", "keywords": ["test_negative_delay", "TestRetryOnErrorEdgeCases", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.22499999660431e-05, "outcome": "passed"}, "call": {"duration": 0.00044679099994482385, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/2): Error\n   \u7b49\u5f85 -1.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/2): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 8.449999995718827e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_zero_delay", "lineno": 310, "outcome": "passed", "keywords": ["test_zero_delay", "TestRetryOnErrorEdgeCases", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.895799996684218e-05, "outcome": "passed"}, "call": {"duration": 0.0004177920000074664, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/2): Error\n   \u7b49\u5f85 0.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/2): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 8.216600008381647e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_large_backoff_multiplier", "lineno": 323, "outcome": "passed", "keywords": ["test_large_backoff_multiplier", "TestRetryOnErrorEdgeCases", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.108299991567037e-05, "outcome": "passed"}, "call": {"duration": 0.0004269580000482165, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/3): Error\n   \u7b49\u5f85 10.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/3): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 0.000606334000053721, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorEdgeCases::test_fractional_backoff", "lineno": 337, "outcome": "passed", "keywords": ["test_fractional_backoff", "TestRetryOnErrorEdgeCases", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.341700001641584e-05, "outcome": "passed"}, "call": {"duration": 0.00043500000003859896, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Error\n   \u7b49\u5f85 1.0 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/3): Error\n   \u7b49\u5f85 0.5 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/3): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 8.4250000099928e-05, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorWithRealSleep::test_actual_delay", "lineno": 355, "outcome": "passed", "keywords": ["test_actual_delay", "TestRetryOnErrorWithRealSleep", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 9.687500005384209e-05, "outcome": "passed"}, "call": {"duration": 0.05274312500000633, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/2): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/2): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 0.00010295799995674315, "outcome": "passed"}}, {"nodeid": "tests/test_retry_decorator.py::TestRetryOnErrorWithRealSleep::test_cumulative_delay", "lineno": 369, "outcome": "passed", "keywords": ["test_cumulative_delay", "TestRetryOnErrorWithRealSleep", "test_retry_decorator.py", "tests", "server", ""], "setup": {"duration": 0.00010454100004153588, "outcome": "passed"}, "call": {"duration": 0.10785108400000354, "outcome": "passed", "stdout": "\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 1/3): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 2/3): Error\n   \u7b49\u5f85 0.1 \u79d2\u540e\u91cd\u8bd5...\n\u26a0\ufe0f API\u8c03\u7528\u5931\u8d25 (\u5c1d\u8bd5 3/3): Error\n\u274c \u8fbe\u5230\u6700\u5927\u91cd\u8bd5\u6b21\u6570\uff0c\u653e\u5f03\n"}, "teardown": {"duration": 0.0001447500000040236, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit::test_init_success", "lineno": 60, "outcome": "passed", "keywords": ["test_init_success", "__wrapped__", "patchings", "TestXfyunIseClientInit", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.00010495900005480507, "outcome": "passed"}, "call": {"duration": 0.00019825000003947935, "outcome": "passed"}, "teardown": {"duration": 8.108300005460478e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit::test_init_missing_app_id", "lineno": 70, "outcome": "passed", "keywords": ["test_init_missing_app_id", "__wrapped__", "patchings", "TestXfyunIseClientInit", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.966600003328494e-05, "outcome": "passed"}, "call": {"duration": 0.0001431670000329177, "outcome": "passed"}, "teardown": {"duration": 7.845900006486772e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestXfyunIseClientInit::test_init_missing_api_key", "lineno": 79, "outcome": "passed", "keywords": ["test_init_missing_api_key", "__wrapped__", "patchings", "TestXfyunIseClientInit", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 8.191699998860713e-05, "outcome": "passed"}, "call": {"duration": 0.00013516600006369117, "outcome": "passed"}, "teardown": {"duration": 6.85420000081649e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestCreateUrl::test_create_url_structure", "lineno": 92, "outcome": "passed", "keywords": ["test_create_url_structure", "__wrapped__", "patchings", "TestCreateUrl", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.52920000195445e-05, "outcome": "passed"}, "call": {"duration": 0.0006744999999455104, "outcome": "passed"}, "teardown": {"duration": 6.970900005853764e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_word_text", "lineno": 114, "outcome": "passed", "keywords": ["test_build_word_text", "__wrapped__", "patchings", "TestBuildIseText", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 8.187499997802661e-05, "outcome": "passed"}, "call": {"duration": 0.0001305419999653168, "outcome": "passed"}, "teardown": {"duration": 7.38750001119115e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_sentence_text", "lineno": 123, "outcome": "passed", "keywords": ["test_build_sentence_text", "__wrapped__", "patchings", "TestBuildIseText", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 8.183299996744609e-05, "outcome": "passed"}, "call": {"duration": 0.0001242499999989377, "outcome": "passed"}, "teardown": {"duration": 6.98750000083237e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_chapter_text", "lineno": 132, "outcome": "passed", "keywords": ["test_build_chapter_text", "__wrapped__", "patchings", "TestBuildIseText", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.662499990601646e-05, "outcome": "passed"}, "call": {"duration": 0.00012020799999845622, "outcome": "passed"}, "teardown": {"duration": 6.837500006895425e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestBuildIseText::test_build_unknown_category", "lineno": 141, "outcome": "passed", "keywords": ["test_build_unknown_category", "__wrapped__", "patchings", "TestBuildIseText", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.550000009359792e-05, "outcome": "passed"}, "call": {"duration": 0.00012066700003288133, "outcome": "passed"}, "teardown": {"duration": 6.912499998179555e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_sentence_result", "lineno": 154, "outcome": "failed", "keywords": ["test_parse_sentence_result", "__wrapped__", "patchings", "TestParseResult", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.00015029199994387454, "outcome": "passed"}, "call": {"duration": 0.0008809999999357387, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/tests/test_xfyun_client.py", "lineno": 163, "message": "assert 0 == 85.5"}, "traceback": [{"path": "tests/test_xfyun_client.py", "lineno": 163, "message": "AssertionError"}], "longrepr": "self = <tests.test_xfyun_client.TestParseResult object at 0x1264e7610>\nsample_xml_result = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<rec_paper total_score=\"85.5\" accuracy_score=\"88.0\" fluency_score=\"83.0\" inte... <syll content=\"ld\" total_score=\"79.0\"/>\\n            </word>\\n        </sentence>\\n    </read_sentence>\\n</rec_paper>'\n\n    @patch(\"services.xfyun_client.XFYUN_APP_ID\", \"test_app_id\")\n    @patch(\"services.xfyun_client.XFYUN_API_KEY\", \"test_api_key\")\n    @patch(\"services.xfyun_client.XFYUN_API_SECRET\", \"test_api_secret\")\n    def test_parse_sentence_result(self, sample_xml_result):\n        \"\"\"\u6d4b\u8bd5\u89e3\u6790\u53e5\u5b50\u8bc4\u6d4b\u7ed3\u679c\"\"\"\n        client = XfyunIseClient()\n        result = client._parse_result(sample_xml_result)\n    \n>       assert result[\"total_score\"] == 85.5\nE       assert 0 == 85.5\n\ntests/test_xfyun_client.py:163: AssertionError"}, "teardown": {"duration": 0.00013470800001869065, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_word_result", "lineno": 171, "outcome": "failed", "keywords": ["test_parse_word_result", "__wrapped__", "patchings", "TestParseResult", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.704100005412329e-05, "outcome": "passed"}, "call": {"duration": 0.00023591699994085502, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/tests/test_xfyun_client.py", "lineno": 187, "message": "assert 0 == 90.0"}, "traceback": [{"path": "tests/test_xfyun_client.py", "lineno": 187, "message": "AssertionError"}], "longrepr": "self = <tests.test_xfyun_client.TestParseResult object at 0x1264e7750>\n\n    @patch(\"services.xfyun_client.XFYUN_APP_ID\", \"test_app_id\")\n    @patch(\"services.xfyun_client.XFYUN_API_KEY\", \"test_api_key\")\n    @patch(\"services.xfyun_client.XFYUN_API_SECRET\", \"test_api_secret\")\n    def test_parse_word_result(self):\n        \"\"\"\u6d4b\u8bd5\u89e3\u6790\u5355\u8bcd\u8bc4\u6d4b\u7ed3\u679c\"\"\"\n        xml = \"\"\"<?xml version=\"1.0\"?>\n        <rec_paper total_score=\"90.0\">\n            <read_word>\n                <word content=\"hello\" total_score=\"90.0\"/>\n            </read_word>\n        </rec_paper>\"\"\"\n    \n        client = XfyunIseClient()\n        result = client._parse_result(xml)\n    \n>       assert result[\"total_score\"] == 90.0\nE       assert 0 == 90.0\n\ntests/test_xfyun_client.py:187: AssertionError"}, "teardown": {"duration": 5.9833000022990745e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_invalid_xml", "lineno": 190, "outcome": "passed", "keywords": ["test_parse_invalid_xml", "__wrapped__", "patchings", "TestParseResult", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 6.083300002046599e-05, "outcome": "passed"}, "call": {"duration": 0.00011383399998976529, "outcome": "passed"}, "teardown": {"duration": 5.0375000000713044e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_syllable_details", "lineno": 201, "outcome": "passed", "keywords": ["test_parse_syllable_details", "__wrapped__", "patchings", "TestParseResult", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 9.466599999541359e-05, "outcome": "passed"}, "call": {"duration": 0.00014229200007775944, "outcome": "passed"}, "teardown": {"duration": 5.441700000119454e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestParseResult::test_parse_dp_message", "lineno": 215, "outcome": "passed", "keywords": ["test_parse_dp_message", "__wrapped__", "patchings", "TestParseResult", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.908299994596746e-05, "outcome": "passed"}, "call": {"duration": 0.0001263329999119378, "outcome": "passed"}, "teardown": {"duration": 5.579100002250925e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio::test_prepare_pcm_audio", "lineno": 230, "outcome": "failed", "keywords": ["test_prepare_pcm_audio", "__wrapped__", "patchings", "TestPrepareAudio", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.000731959000063398, "outcome": "passed"}, "call": {"duration": 0.0030941250000751097, "outcome": "failed", "crash": {"path": "/Users/ruiwang/Desktop/speakingtest/server/venv/lib/python3.14/site-packages/pydub/utils.py", "lineno": 16, "message": "ModuleNotFoundError: No module named 'pyaudioop'"}, "traceback": [{"path": "tests/test_xfyun_client.py", "lineno": 245, "message": ""}, {"path": "services/xfyun_client.py", "lineno": 226, "message": "in _prepare_audio"}, {"path": "venv/lib/python3.14/site-packages/pydub/__init__.py", "lineno": 1, "message": "in <module>"}, {"path": "venv/lib/python3.14/site-packages/pydub/audio_segment.py", "lineno": 11, "message": "in <module>"}, {"path": "venv/lib/python3.14/site-packages/pydub/utils.py", "lineno": 16, "message": "ModuleNotFoundError"}], "longrepr": "from __future__ import division\n    \n    import json\n    import os\n    import re\n    import sys\n    from subprocess import Popen, PIPE\n    from math import log, ceil\n    from tempfile import TemporaryFile\n    from warnings import warn\n    from functools import wraps\n    \n    try:\n>       import audioop\nE       ModuleNotFoundError: No module named 'audioop'\n\nvenv/lib/python3.14/site-packages/pydub/utils.py:14: ModuleNotFoundError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <tests.test_xfyun_client.TestPrepareAudio object at 0x1264e7890>\nsample_audio_file = '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_prepare_pcm_audio0/test_audio.wav'\n\n    @patch(\"services.xfyun_client.XFYUN_APP_ID\", \"test_app_id\")\n    @patch(\"services.xfyun_client.XFYUN_API_KEY\", \"test_api_key\")\n    @patch(\"services.xfyun_client.XFYUN_API_SECRET\", \"test_api_secret\")\n    def test_prepare_pcm_audio(self, sample_audio_file):\n        \"\"\"\u6d4b\u8bd5\u51c6\u5907 PCM \u97f3\u9891\"\"\"\n        # \u5c06\u6587\u4ef6\u6539\u4e3a .pcm \u6269\u5c55\u540d\n        pcm_file = sample_audio_file.replace(\".wav\", \".pcm\")\n        import os\n        os.rename(sample_audio_file, pcm_file)\n    \n        with open(pcm_file, \"wb\") as f:\n            f.write(b\"pcm data\")\n    \n        client = XfyunIseClient()\n>       result = client._prepare_audio(pcm_file)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\ntests/test_xfyun_client.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \nservices/xfyun_client.py:226: in _prepare_audio\n    from pydub import AudioSegment\nvenv/lib/python3.14/site-packages/pydub/__init__.py:1: in <module>\n    from .audio_segment import AudioSegment\nvenv/lib/python3.14/site-packages/pydub/audio_segment.py:11: in <module>\n    from .utils import mediainfo_json, fsdecode\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    from __future__ import division\n    \n    import json\n    import os\n    import re\n    import sys\n    from subprocess import Popen, PIPE\n    from math import log, ceil\n    from tempfile import TemporaryFile\n    from warnings import warn\n    from functools import wraps\n    \n    try:\n        import audioop\n    except ImportError:\n>       import pyaudioop as audioop\nE       ModuleNotFoundError: No module named 'pyaudioop'\n\nvenv/lib/python3.14/site-packages/pydub/utils.py:16: ModuleNotFoundError"}, "teardown": {"duration": 0.00014312499990865035, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio::test_prepare_wav_audio", "lineno": 248, "outcome": "failed", "keywords": ["test_prepare_wav_audio", "__wrapped__", "patchings", "TestPrepareAudio", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.0006363749999991342, "outcome": "passed"}, "call": {"duration": 9.499999998752173e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestPrepareAudio object at 0x1264e79d0>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_prepare_wav_audio0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x1265384b0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.0001402499999585416, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestPrepareAudio::test_prepare_webm_audio", "lineno": 269, "outcome": "failed", "keywords": ["test_prepare_webm_audio", "__wrapped__", "patchings", "TestPrepareAudio", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.000589624999975058, "outcome": "passed"}, "call": {"duration": 8.795799999461451e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestPrepareAudio object at 0x1265548a0>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_prepare_webm_audio0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12653a510>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.0001388330000509086, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio::test_evaluate_audio_success", "lineno": 297, "outcome": "failed", "keywords": ["test_evaluate_audio_success", "__wrapped__", "patchings", "TestEvaluateAudio", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.0005787909999526164, "outcome": "passed"}, "call": {"duration": 9.129199997914839e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestEvaluateAudio object at 0x1264e7b10>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_evaluate_audio_success0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12653aa50>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00014937499997813575, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio::test_evaluate_audio_error_code", "lineno": 339, "outcome": "failed", "keywords": ["test_evaluate_audio_error_code", "__wrapped__", "patchings", "TestEvaluateAudio", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.0006745839999666714, "outcome": "passed"}, "call": {"duration": 0.00013804100001379993, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestEvaluateAudio object at 0x1264e7c50>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_evaluate_audio_error_code0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12653aeb0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00012733300002309988, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudio::test_evaluate_audio_websocket_error", "lineno": 371, "outcome": "failed", "keywords": ["test_evaluate_audio_websocket_error", "__wrapped__", "patchings", "TestEvaluateAudio", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.0005842910001092605, "outcome": "passed"}, "call": {"duration": 9.083299994472327e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestEvaluateAudio object at 0x1265549d0>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_evaluate_audio_websocket_0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12653b310>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00011666699992929352, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudioParameters::test_evaluate_with_category_read_word", "lineno": 403, "outcome": "failed", "keywords": ["test_evaluate_with_category_read_word", "__wrapped__", "patchings", "TestEvaluateAudioParameters", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.000528791999954592, "outcome": "passed"}, "call": {"duration": 8.324999998876592e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestEvaluateAudioParameters object at 0x1264e7d90>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_evaluate_with_category_re0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12653b770>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00010437500009174983, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestEvaluateAudioParameters::test_evaluate_with_language_chinese", "lineno": 442, "outcome": "failed", "keywords": ["test_evaluate_with_language_chinese", "__wrapped__", "patchings", "TestEvaluateAudioParameters", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 0.0005311669999628066, "outcome": "passed"}, "call": {"duration": 7.708399994044157e-05, "outcome": "failed", "crash": {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'"}, "traceback": [{"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1429, "message": ""}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 141, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1411, "message": "in decoration_helper"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py", "lineno": 530, "message": "in enter_context"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1503, "message": "in __enter__"}, {"path": "/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py", "lineno": 1473, "message": "AttributeError"}], "longrepr": "args = (<tests.test_xfyun_client.TestEvaluateAudioParameters object at 0x1264e7ed0>,)\nkeywargs = {'sample_audio_file': '/private/var/folders/qw/f2q7yvr95yv7rpnd6cq1zpz80000gn/T/pytest-of-ruiwang/pytest-1/test_evaluate_with_language_ch0/test_audio.wav'}\n\n    @wraps(func)\n    def patched(*args, **keywargs):\n>       with self.decoration_helper(patched,\n                                    args,\n                                    keywargs) as (newargs, newkeywargs):\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:141: in __enter__\n    return next(self.gen)\n           ^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1411: in decoration_helper\n    arg = exit_stack.enter_context(patching)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/contextlib.py:530: in enter_context\n    result = _enter(cm)\n             ^^^^^^^^^^\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1503: in __enter__\n    original, local = self.get_original()\n                      ^^^^^^^^^^^^^^^^^^^\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <unittest.mock._patch object at 0x12653bbd0>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'services.xfyun_client' from '/Users/ruiwang/Desktop/speakingtest/server/services/xfyun_client.py'> does not have the attribute 'AudioSegment'\n\n/opt/homebrew/Cellar/python@3.14/3.14.0_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/unittest/mock.py:1473: AttributeError"}, "teardown": {"duration": 0.00014241600001696497, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestGetGlobalClient::test_get_client_first_time", "lineno": 485, "outcome": "passed", "keywords": ["test_get_client_first_time", "__wrapped__", "patchings", "TestGetGlobalClient", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 7.129200002964353e-05, "outcome": "passed"}, "call": {"duration": 9.583300004578632e-05, "outcome": "passed"}, "teardown": {"duration": 4.341699991528003e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestGetGlobalClient::test_get_client_missing_config", "lineno": 495, "outcome": "passed", "keywords": ["test_get_client_missing_config", "__wrapped__", "patchings", "TestGetGlobalClient", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 4.987500005881884e-05, "outcome": "passed"}, "call": {"duration": 0.00019945799999732117, "outcome": "passed"}, "teardown": {"duration": 3.487499998300336e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_client.py::TestModuleConstants::test_ise_url", "lineno": 510, "outcome": "passed", "keywords": ["test_ise_url", "TestModuleConstants", "test_xfyun_client.py", "tests", "server", ""], "setup": {"duration": 3.970800003116892e-05, "outcome": "passed"}, "call": {"duration": 4.158299998380244e-05, "outcome": "passed"}, "teardown": {"duration": 3.591600000163453e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_success", "lineno": 49, "outcome": "passed", "keywords": ["test_evaluate_words_success", "__wrapped__", "patchings", "TestEvaluateWordsWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0005273749999332722, "outcome": "passed"}, "call": {"duration": 0.0001837500000192449, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 1: 3 \u4e2a\u5355\u8bcd\n"}, "teardown": {"duration": 4.320899995491345e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_partial_correct", "lineno": 65, "outcome": "passed", "keywords": ["test_evaluate_words_partial_correct", "__wrapped__", "patchings", "TestEvaluateWordsWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0003729579999571797, "outcome": "passed"}, "call": {"duration": 0.00015087500003119203, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 1: 3 \u4e2a\u5355\u8bcd\n"}, "teardown": {"duration": 3.9500000070802344e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_client_none", "lineno": 93, "outcome": "passed", "keywords": ["test_evaluate_words_client_none", "__wrapped__", "patchings", "TestEvaluateWordsWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0003575419999606311, "outcome": "passed"}, "call": {"duration": 9.637499999826105e-05, "outcome": "passed"}, "teardown": {"duration": 4.116600007364468e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_api_error", "lineno": 104, "outcome": "passed", "keywords": ["test_evaluate_words_api_error", "__wrapped__", "patchings", "TestEvaluateWordsWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00035791599998447055, "outcome": "passed"}, "call": {"duration": 0.00013970800000606687, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 1: 1 \u4e2a\u5355\u8bcd\n\u274c \u8baf\u98de\u8bc4\u6d4b\u5931\u8d25: Connection failed\n"}, "teardown": {"duration": 4.1083000041908235e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_exception", "lineno": 119, "outcome": "passed", "keywords": ["test_evaluate_words_exception", "__wrapped__", "patchings", "TestEvaluateWordsWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.000341042000059133, "outcome": "passed"}, "call": {"duration": 0.00014175000001159788, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 1: 1 \u4e2a\u5355\u8bcd\n\u274c \u8baf\u98de\u8bc4\u6d4b\u5f02\u5e38: Unexpected error\n"}, "teardown": {"duration": 3.979199993864313e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateWordsWithXfyun::test_evaluate_words_low_score", "lineno": 131, "outcome": "passed", "keywords": ["test_evaluate_words_low_score", "__wrapped__", "patchings", "TestEvaluateWordsWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0003539999999020438, "outcome": "passed"}, "call": {"duration": 0.00014845800001239695, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 1: 3 \u4e2a\u5355\u8bcd\n"}, "teardown": {"duration": 3.9667000010013e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_success", "lineno": 160, "outcome": "passed", "keywords": ["test_evaluate_sentence_success", "__wrapped__", "patchings", "TestEvaluateSentenceWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00034958300000198506, "outcome": "passed"}, "call": {"duration": 0.00013779200003227743, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2 \u95ee\u9898 1\n"}, "teardown": {"duration": 3.9874999970379577e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_score_conversion", "lineno": 184, "outcome": "passed", "keywords": ["test_evaluate_sentence_score_conversion", "__wrapped__", "patchings", "TestEvaluateSentenceWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0003559580000001006, "outcome": "passed"}, "call": {"duration": 0.00013454199995521776, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2 \u95ee\u9898 1\n"}, "teardown": {"duration": 4.2290999999750056e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_client_none", "lineno": 207, "outcome": "passed", "keywords": ["test_evaluate_sentence_client_none", "__wrapped__", "patchings", "TestEvaluateSentenceWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00033829100004822976, "outcome": "passed"}, "call": {"duration": 9.249999993699021e-05, "outcome": "passed"}, "teardown": {"duration": 3.983400006291049e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluateSentenceWithXfyun::test_evaluate_sentence_with_index", "lineno": 218, "outcome": "passed", "keywords": ["test_evaluate_sentence_with_index", "__wrapped__", "patchings", "TestEvaluateSentenceWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00034887499998603744, "outcome": "passed"}, "call": {"duration": 0.0001336250001031658, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2 \u95ee\u9898 5\n"}, "teardown": {"duration": 4.091699997843534e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_success", "lineno": 243, "outcome": "passed", "keywords": ["test_evaluate_part2_all_success", "__wrapped__", "patchings", "TestEvaluatePart2AllWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0003569579999975758, "outcome": "passed"}, "call": {"duration": 0.0003366249999317006, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2: 12 \u4e2a\u95ee\u9898\u7684\u7efc\u5408\u56de\u7b54\n"}, "teardown": {"duration": 4.1084000031332835e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_score_distribution", "lineno": 267, "outcome": "passed", "keywords": ["test_evaluate_part2_all_score_distribution", "__wrapped__", "patchings", "TestEvaluatePart2AllWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0003451250000807704, "outcome": "passed"}, "call": {"duration": 0.0001427079999984926, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2: 12 \u4e2a\u95ee\u9898\u7684\u7efc\u5408\u56de\u7b54\n"}, "teardown": {"duration": 4.2042000018227554e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_client_none", "lineno": 292, "outcome": "passed", "keywords": ["test_evaluate_part2_all_client_none", "__wrapped__", "patchings", "TestEvaluatePart2AllWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00034079199997449905, "outcome": "passed"}, "call": {"duration": 9.162499998183193e-05, "outcome": "passed"}, "teardown": {"duration": 3.9832999959799054e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestEvaluatePart2AllWithXfyun::test_evaluate_part2_all_uses_chapter_mode", "lineno": 302, "outcome": "passed", "keywords": ["test_evaluate_part2_all_uses_chapter_mode", "__wrapped__", "patchings", "TestEvaluatePart2AllWithXfyun", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00035383299996283313, "outcome": "passed"}, "call": {"duration": 0.0001440830000092319, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2: 12 \u4e2a\u95ee\u9898\u7684\u7efc\u5408\u56de\u7b54\n"}, "teardown": {"duration": 4.04169999228543e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_correct", "lineno": 331, "outcome": "passed", "keywords": ["test_dp_message_correct", "TestGetDpMessageText", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.7084000041431864e-05, "outcome": "passed"}, "call": {"duration": 3.9375000028485374e-05, "outcome": "passed"}, "teardown": {"duration": 3.1625000019630534e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_missed", "lineno": 335, "outcome": "passed", "keywords": ["test_dp_message_missed", "TestGetDpMessageText", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.716599997005687e-05, "outcome": "passed"}, "call": {"duration": 4.1666000015538884e-05, "outcome": "passed"}, "teardown": {"duration": 3.216599998268066e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_added", "lineno": 339, "outcome": "passed", "keywords": ["test_dp_message_added", "TestGetDpMessageText", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 4.0333000015380094e-05, "outcome": "passed"}, "call": {"duration": 4.091699997843534e-05, "outcome": "passed"}, "teardown": {"duration": 3.3583000004000496e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_repeated", "lineno": 343, "outcome": "passed", "keywords": ["test_dp_message_repeated", "TestGetDpMessageText", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.941699992537906e-05, "outcome": "passed"}, "call": {"duration": 4.208300003938348e-05, "outcome": "passed"}, "teardown": {"duration": 3.254200009905617e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_replaced", "lineno": 347, "outcome": "passed", "keywords": ["test_dp_message_replaced", "TestGetDpMessageText", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.8417000041590654e-05, "outcome": "passed"}, "call": {"duration": 4.295799999454175e-05, "outcome": "passed"}, "teardown": {"duration": 3.5874999980478606e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGetDpMessageText::test_dp_message_unknown", "lineno": 351, "outcome": "passed", "keywords": ["test_dp_message_unknown", "TestGetDpMessageText", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 4.024999998364365e-05, "outcome": "passed"}, "call": {"duration": 4.037499991227378e-05, "outcome": "passed"}, "teardown": {"duration": 3.4540999990895216e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_all_correct", "lineno": 359, "outcome": "passed", "keywords": ["test_feedback_all_correct", "TestGeneratePart1Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.983400006291049e-05, "outcome": "passed"}, "call": {"duration": 4.462499998680869e-05, "outcome": "passed"}, "teardown": {"duration": 3.049999997983832e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_mostly_correct", "lineno": 373, "outcome": "passed", "keywords": ["test_feedback_mostly_correct", "TestGeneratePart1Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.583399995932268e-05, "outcome": "passed"}, "call": {"duration": 4.162499999438296e-05, "outcome": "passed"}, "teardown": {"duration": 3.3666999911474704e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_half_correct", "lineno": 390, "outcome": "passed", "keywords": ["test_feedback_half_correct", "TestGeneratePart1Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.837500003101013e-05, "outcome": "passed"}, "call": {"duration": 4.1541999962646514e-05, "outcome": "passed"}, "teardown": {"duration": 3.075000006447226e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart1Feedback::test_feedback_poor", "lineno": 405, "outcome": "passed", "keywords": ["test_feedback_poor", "TestGeneratePart1Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.470899991953047e-05, "outcome": "passed"}, "call": {"duration": 4.041700003654114e-05, "outcome": "passed"}, "teardown": {"duration": 3.195800002231408e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_excellent", "lineno": 423, "outcome": "passed", "keywords": ["test_feedback_excellent", "TestGeneratePart2Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.641600005721557e-05, "outcome": "passed"}, "call": {"duration": 3.849999995964026e-05, "outcome": "passed"}, "teardown": {"duration": 3.5124999953950464e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_good", "lineno": 428, "outcome": "passed", "keywords": ["test_feedback_good", "TestGeneratePart2Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.729100001237384e-05, "outcome": "passed"}, "call": {"duration": 3.9542000081382866e-05, "outcome": "passed"}, "teardown": {"duration": 3.437499992742232e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_average", "lineno": 433, "outcome": "passed", "keywords": ["test_feedback_average", "TestGeneratePart2Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.591699999105913e-05, "outcome": "passed"}, "call": {"duration": 3.754199997274554e-05, "outcome": "passed"}, "teardown": {"duration": 2.974999995331018e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2Feedback::test_feedback_poor", "lineno": 438, "outcome": "passed", "keywords": ["test_feedback_poor", "TestGeneratePart2Feedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.5499999967214535e-05, "outcome": "passed"}, "call": {"duration": 3.912500005753827e-05, "outcome": "passed"}, "teardown": {"duration": 3.5749999938161636e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_excellent", "lineno": 447, "outcome": "passed", "keywords": ["test_overall_feedback_excellent", "TestGeneratePart2OverallFeedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.616699996200623e-05, "outcome": "passed"}, "call": {"duration": 3.908399992269551e-05, "outcome": "passed"}, "teardown": {"duration": 3.166699991652422e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_good", "lineno": 454, "outcome": "passed", "keywords": ["test_overall_feedback_good", "TestGeneratePart2OverallFeedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.5749999938161636e-05, "outcome": "passed"}, "call": {"duration": 3.8666000023113156e-05, "outcome": "passed"}, "teardown": {"duration": 2.987499999562715e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_average", "lineno": 459, "outcome": "passed", "keywords": ["test_overall_feedback_average", "TestGeneratePart2OverallFeedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.5874999980478606e-05, "outcome": "passed"}, "call": {"duration": 4.033400000480469e-05, "outcome": "passed"}, "teardown": {"duration": 3.3208999980161025e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_low_accuracy", "lineno": 464, "outcome": "passed", "keywords": ["test_overall_feedback_low_accuracy", "TestGeneratePart2OverallFeedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.7416999930428574e-05, "outcome": "passed"}, "call": {"duration": 3.8874999972904334e-05, "outcome": "passed"}, "teardown": {"duration": 3.0042000048524642e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_low_fluency", "lineno": 469, "outcome": "passed", "keywords": ["test_overall_feedback_low_fluency", "TestGeneratePart2OverallFeedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.595800001221505e-05, "outcome": "passed"}, "call": {"duration": 3.99159999915355e-05, "outcome": "passed"}, "teardown": {"duration": 3.0541000000994245e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestGeneratePart2OverallFeedback::test_overall_feedback_combined", "lineno": 474, "outcome": "passed", "keywords": ["test_overall_feedback_combined", "TestGeneratePart2OverallFeedback", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.616699996200623e-05, "outcome": "passed"}, "call": {"duration": 3.837500003101013e-05, "outcome": "passed"}, "teardown": {"duration": 3.533400001742848e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestIsXfyunConfigured::test_configured", "lineno": 484, "outcome": "passed", "keywords": ["test_configured", "__wrapped__", "patchings", "TestIsXfyunConfigured", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 3.762500000448199e-05, "outcome": "passed"}, "call": {"duration": 9.879100002763153e-05, "outcome": "passed"}, "teardown": {"duration": 6.137500008662755e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestIsXfyunConfigured::test_not_configured", "lineno": 490, "outcome": "passed", "keywords": ["test_not_configured", "__wrapped__", "patchings", "TestIsXfyunConfigured", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 5.141700000876881e-05, "outcome": "passed"}, "call": {"duration": 0.00014308300001175667, "outcome": "passed"}, "teardown": {"duration": 4.124999998111889e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestScoreCalculations::test_part2_score_calculation", "lineno": 500, "outcome": "passed", "keywords": ["test_part2_score_calculation", "__wrapped__", "patchings", "TestScoreCalculations", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.0005062919999545556, "outcome": "passed"}, "call": {"duration": 0.00016762500001732406, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2: 12 \u4e2a\u95ee\u9898\u7684\u7efc\u5408\u56de\u7b54\n"}, "teardown": {"duration": 4.595799998696748e-05, "outcome": "passed"}}, {"nodeid": "tests/test_xfyun_scorer.py::TestScoreCalculations::test_part2_half_score", "lineno": 525, "outcome": "passed", "keywords": ["test_part2_half_score", "__wrapped__", "patchings", "TestScoreCalculations", "test_xfyun_scorer.py", "tests", "server", ""], "setup": {"duration": 0.00037429200006044994, "outcome": "passed"}, "call": {"duration": 0.00014999999996234692, "outcome": "passed", "stdout": "\ud83d\udcca \u8baf\u98de\u8bc4\u6d4b Part 2: 12 \u4e2a\u95ee\u9898\u7684\u7efc\u5408\u56de\u7b54\n"}, "teardown": {"duration": 0.0002511669999876176, "outcome": "passed"}}], "warnings": [{"message": "The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)", "category": "MovedIn20Warning", "when": "collect", "filename": "/Users/ruiwang/Desktop/speakingtest/server/database.py", "lineno": 39}, {"message": "Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/Users/ruiwang/Desktop/speakingtest/server/schemas.py", "lineno": 9}, {"message": "Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/", "category": "PydanticDeprecatedSince20", "when": "collect", "filename": "/Users/ruiwang/Desktop/speakingtest/server/schemas.py", "lineno": 22}, {"message": "'_UnionGenericAlias' is deprecated and slated for removal in Python 3.17", "category": "DeprecationWarning", "when": "collect", "filename": "/Users/ruiwang/Desktop/speakingtest/server/venv/lib/python3.14/site-packages/google/genai/types.py", "lineno": 43}]}