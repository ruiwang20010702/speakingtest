#!/usr/bin/env python3
"""
Qwen3-Omni-Flash å£è¯­æµ‹è¯„æµ‹è¯•è„šæœ¬ (ç»“æ„åŒ–è¾“å‡ºç‰ˆ)
ä½¿ç”¨ OpenAI å…¼å®¹åè®®è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°çš„ Qwen3-Omni-Flash æ¨¡å‹ï¼Œå¹¶è¦æ±‚è¿”å› JSON æ ¼å¼æ•°æ®
"""

import os
import base64
import json
from pathlib import Path
from openai import OpenAI

# ============================================
# é…ç½®
# ============================================

# API Key ä»ç¯å¢ƒå˜é‡è·å–ï¼Œæˆ–ç›´æ¥å¡«å†™
API_KEY = os.getenv("DASHSCOPE_API_KEY") or "sk-038d7badfa974ca9850ed879dae34a47"

# æ¨¡å‹åç§°
MODEL = "qwen3-omni-flash"

# ç™¾ç‚¼å¹³å° OpenAI å…¼å®¹ base_url
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"


def create_client():
    """åˆ›å»º OpenAI å®¢æˆ·ç«¯"""
    if not API_KEY:
        raise ValueError(
            "è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼Œæˆ–åœ¨ä»£ç ä¸­ç›´æ¥å¡«å†™ API_KEY\n"
            "è·å–æ–¹å¼ï¼šhttps://bailian.console.aliyun.com/"
        )
    
    return OpenAI(
        api_key=API_KEY,
        base_url=BASE_URL,
    )


def load_audio_file(audio_path: str) -> tuple[str, str, str]:
    """
    åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶è½¬æ¢ä¸º base64
    
    Returns:
        tuple: (base64ç¼–ç çš„éŸ³é¢‘æ•°æ®, éŸ³é¢‘æ ¼å¼, data URL)
    """
    path = Path(audio_path)
    
    if not path.exists():
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
    
    # è·å–éŸ³é¢‘æ ¼å¼å’Œ MIME ç±»å‹
    suffix = path.suffix.lower()
    format_map = {
        ".mp3": ("mp3", "audio/mpeg"),
        ".wav": ("wav", "audio/wav"),
        ".pcm": ("pcm", "audio/pcm"),
        ".m4a": ("m4a", "audio/mp4"),
        ".flac": ("flac", "audio/flac"),
    }
    
    if suffix not in format_map:
        raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {suffix}")
    
    audio_format, mime_type = format_map[suffix]
    
    # è¯»å–å¹¶ç¼–ç 
    with open(path, "rb") as f:
        audio_data = base64.b64encode(f.read()).decode("utf-8")
    
    # æ„å»º data URL
    data_url = f"data:{mime_type};base64,{audio_data}"
    
    print(f"âœ… å·²åŠ è½½éŸ³é¢‘æ–‡ä»¶: {path.name} ({path.stat().st_size / 1024:.1f} KB)")
    
    return audio_data, audio_format, data_url


# å®šä¹‰è¾“å‡ºçš„ JSON Schema
EVALUATION_SCHEMA = {
    "type": "json_schema",
    "json_schema": {
        "name": "speaking_evaluation",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "transcription": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "integer"},
                            "question": {"type": "string"},
                            "answer": {"type": "string"}
                        },
                        "required": ["id", "question", "answer"],
                        "additionalProperties": False
                    }
                },
                "scores": {
                    "type": "object",
                    "properties": {
                        "pronunciation": {"type": "integer", "description": "Score from 1-10"},
                        "grammar": {"type": "integer", "description": "Score from 1-10"},
                        "fluency": {"type": "integer", "description": "Score from 1-10"},
                        "content": {"type": "integer", "description": "Score from 1-10"},
                        "overall": {"type": "integer", "description": "Score from 1-10"}
                    },
                    "required": ["pronunciation", "grammar", "fluency", "content", "overall"],
                    "additionalProperties": False
                },
                "question_details": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "integer"},
                            "score": {"type": "integer"},
                            "comment": {"type": "string"}
                        },
                        "required": ["id", "score", "comment"],
                        "additionalProperties": False
                    }
                },
                "pronunciation_issues": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "word": {"type": "string"},
                            "issue": {"type": "string"}
                        },
                        "required": ["word", "issue"],
                        "additionalProperties": False
                    }
                },
                "grammar_issues": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "original": {"type": "string"},
                            "corrected": {"type": "string"},
                            "explanation": {"type": "string"}
                        },
                        "required": ["original", "corrected", "explanation"],
                        "additionalProperties": False
                    }
                },
                "suggestions": {
                    "type": "array",
                    "items": {"type": "string"}
                }
            },
            "required": [
                "transcription",
                "scores",
                "question_details",
                "pronunciation_issues",
                "grammar_issues",
                "suggestions"
            ],
            "additionalProperties": False
        }
    }
}


def evaluate_speaking(
    client: OpenAI,
    audio_path: str,
    question_context: str,
) -> dict:
    """
    ä½¿ç”¨ Qwen3-Omni è¯„æµ‹å£è¯­ï¼Œè¿”å›ç»“æ„åŒ– JSON æ•°æ®
    """
    # åŠ è½½éŸ³é¢‘
    audio_base64, audio_format, data_url = load_audio_file(audio_path)
    
    # æ„å»º Prompt
    system_prompt = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‹±è¯­å£è¯­è¯„æµ‹è€å¸ˆã€‚è¯·å¬å–å­¦ç”Ÿçš„å½•éŸ³ï¼Œå¹¶æ ¹æ®æä¾›çš„é—®é¢˜åˆ—è¡¨è¿›è¡Œè¯„æµ‹ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„ JSON æ ¼å¼è¾“å‡ºè¯„æµ‹ç»“æœã€‚

**è¯„åˆ†æ ‡å‡†ï¼ˆ1-10åˆ†ï¼‰**ï¼š
- **å‘éŸ³å‡†ç¡®åº¦ (Pronunciation)**: 
  - 9-10: å‘éŸ³æ¸…æ™°ã€æ ‡å‡†ï¼Œæ— æ˜æ˜¾å£éŸ³ï¼Œå…ƒéŸ³/è¾…éŸ³å‘éŸ³å‡†ç¡®ã€‚
  - 7-8: å‘éŸ³è¾ƒæ¸…æ™°ï¼Œæœ‰ä¸ªåˆ«å•è¯å‘éŸ³ä¸å‡†ï¼Œä½†ä¸å½±å“ç†è§£ã€‚
  - 5-6: æœ‰æ˜æ˜¾å£éŸ³ï¼Œéƒ¨åˆ†å•è¯å‘éŸ³é”™è¯¯ï¼Œå½±å“ç†è§£ã€‚
  - 1-4: å‘éŸ³å«ç³Šä¸æ¸…ï¼Œéš¾ä»¥ç†è§£ã€‚
- **è¯­æ³•æ­£ç¡®æ€§ (Grammar)**:
  - 9-10: è¯­æ³•ç»“æ„æ­£ç¡®ï¼Œæ—¶æ€ã€å•å¤æ•°ä½¿ç”¨å¾—å½“ã€‚
  - 7-8: å¶æœ‰å°é”™è¯¯ï¼ˆå¦‚å•å¤æ•°ã€å† è¯ï¼‰ï¼Œä½†ä¸å½±å“å¥æ„ã€‚
  - 5-6: è¯­æ³•é”™è¯¯è¾ƒå¤šï¼Œå½±å“å¥å­ç»“æ„çš„å®Œæ•´æ€§ã€‚
  - 1-4: è¯­æ³•é”™è¯¯ä¸¥é‡ï¼Œæ— æ³•æ„æˆå®Œæ•´å¥å­ã€‚
- **æµåˆ©åº¦ (Fluency)**:
  - 9-10: è¯­é€Ÿé€‚ä¸­ï¼Œåœé¡¿è‡ªç„¶ï¼Œè¿è´¯æ€§å¥½ã€‚
  - 7-8: ç¨æœ‰åœé¡¿æˆ–é‡å¤ï¼Œä½†æ•´ä½“æµç•…ã€‚
  - 5-6: åœé¡¿è¾ƒå¤šï¼Œè¯­é€Ÿç¼“æ…¢ï¼Œæœ‰æ˜æ˜¾çš„çŠ¹è±«ã€‚
  - 1-4: æä¸æµåˆ©ï¼Œé¢‘ç¹å¡é¡¿ã€‚
- **å†…å®¹å®Œæ•´æ€§ (Content)**:
  - 9-10: å›ç­”åˆ‡é¢˜ï¼Œå†…å®¹ä¸°å¯Œå®Œæ•´ï¼Œé€»è¾‘æ¸…æ™°ã€‚
  - 7-8: å›ç­”åŸºæœ¬åˆ‡é¢˜ï¼Œå†…å®¹è¾ƒå®Œæ•´ã€‚
  - 5-6: å›ç­”éƒ¨åˆ†åˆ‡é¢˜ï¼Œå†…å®¹é—æ¼è¾ƒå¤šã€‚
  - 1-4: ç­”éæ‰€é—®æˆ–æœªå›ç­”ã€‚
"""
    
    user_prompt = f"""
è¯·è¯„æµ‹è¿™æ®µå½•éŸ³ã€‚

**æµ‹è¯•é¢˜ç›®**:
{question_context}

è¯·åˆ†æå­¦ç”Ÿçš„å›ç­”ï¼ŒåŒ…æ‹¬è¯­éŸ³è½¬å†™ã€å„é¡¹è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰ã€æ¯é“é¢˜çš„è¯¦ç»†ç‚¹è¯„ã€å‘éŸ³é—®é¢˜ã€è¯­æ³•é—®é¢˜ä»¥åŠæ”¹è¿›å»ºè®®ã€‚
"""
    
    print(f"\nğŸ¯ æ­£åœ¨è°ƒç”¨ {MODEL} è¿›è¡Œç»“æ„åŒ–è¯„æµ‹...")
    print("-" * 50)
    
    try:
        completion = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_audio",
                            "input_audio": {
                                "data": data_url,
                                "format": audio_format
                            }
                        },
                        {
                            "type": "text",
                            "text": user_prompt
                        }
                    ]
                }
            ],
            modalities=["text"],  # æš‚æ—¶åªè·å–æ–‡æœ¬ï¼ˆJSONï¼‰
            response_format=EVALUATION_SCHEMA, # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
            stream=False,
        )
        
        # è·å–å“åº”å†…å®¹
        result_text = completion.choices[0].message.content
        usage_info = completion.usage
        
        print("\n" + "-" * 50)
        
        # è§£æ JSON
        try:
            evaluation_json = json.loads(result_text)
            return {
                "success": True,
                "data": evaluation_json,
                "usage": {
                    "prompt_tokens": usage_info.prompt_tokens if usage_info else 0,
                    "completion_tokens": usage_info.completion_tokens if usage_info else 0,
                    "total_tokens": usage_info.total_tokens if usage_info else 0,
                } if usage_info else {}
            }
        except json.JSONDecodeError:
            return {
                "success": False,
                "error": "æ— æ³•è§£ææ¨¡å‹è¿”å›çš„ JSON",
                "raw_output": result_text
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
        }


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤ Qwen3-Omni ç»“æ„åŒ–å£è¯­æµ‹è¯„æµ‹è¯•")
    print("=" * 60)
    
    client = create_client()
    
    # Part 2 é—®é¢˜åˆ—è¡¨
    part2_questions = """Part 2: Sentences - Question & Answer
1. How are you?
2. Are you happy today?
3. How old are you?
4. What grade are you in?
5. Do you have sisters or brothers?
6. How many sisters or brothers do you have?
7. What can you see in your room?
8. What time is it now?
9. When do you wake up?
10. What is your favorite food?
11. Do you like English?
12. Can you count from one to twenty?"""
    
    # ä½¿ç”¨è½¬æ¢åçš„ MP3 æ–‡ä»¶
    audio_file = "test_converted.mp3"
    
    if Path(audio_file).exists():
        result = evaluate_speaking(
            client=client,
            audio_path=audio_file,
            question_context=part2_questions
        )
        
        if result["success"]:
            print("\nâœ… è¯„æµ‹æˆåŠŸï¼è§£æåçš„æ•°æ®ï¼š")
            print(json.dumps(result["data"], indent=2, ensure_ascii=False))
            print(f"\nğŸ’° Token ä½¿ç”¨: {result['usage']}")
        else:
            print(f"\nâŒ è¯„æµ‹å¤±è´¥: {result['error']}")
    else:
        print(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file} (è¯·å…ˆè¿è¡Œä¹‹å‰çš„è½¬æ¢å‘½ä»¤)")

if __name__ == "__main__":
    main()

